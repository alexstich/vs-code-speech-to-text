// The module 'vscode' contains the VS Code extensibility API
// Import the module and reference it with the alias vscode in your code below
import * as vscode from 'vscode';
import { FFmpegAudioRecorder, AudioRecorderEvents } from './core/FFmpegAudioRecorder';
import { WhisperClient } from './core/WhisperClient';
import { TextInserter } from './ui/TextInserter';
import { StatusBarManager, StatusBarEvents, StatusBarConfiguration } from './ui/StatusBarManager';
import { AudioSettingsProvider, AudioDevice } from './ui/AudioSettingsProvider';
import { DiagnosticsProvider } from './ui/DiagnosticsProvider';
import { ErrorHandler, ErrorType, ErrorContext, VSCodeErrorDisplayHandler } from './utils/ErrorHandler';
import { RetryManager } from './utils/RetryManager';
import { RecoveryActionHandler, RecoveryDependencies } from './utils/RecoveryActionHandler';
import { ContextManager, IDEType, ContextType, IDEContext, ContextManagerEvents } from './core/ContextManager';

// –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
let audioRecorder: FFmpegAudioRecorder | null = null;
let whisperClient: WhisperClient;
let textInserter: TextInserter;
let statusBarManager: StatusBarManager;

// –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
let errorHandler: ErrorHandler;
let retryManager: RetryManager;
let recoveryHandler: RecoveryActionHandler;

// –ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ IDE
let contextManager: ContextManager;

// –°–æ—Å—Ç–æ—è–Ω–∏–µ hold-to-record
let isHoldToRecordActive = false;
let holdToRecordDisposable: vscode.Disposable | null = null;

// –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
let extensionContext: vscode.ExtensionContext;

// –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
let lastTranscribedText: string | null = null;

// UI –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–ª—è –±–æ–∫–æ–≤—ã—Ö –ø–∞–Ω–µ–ª–µ–π
let audioSettingsProvider: AudioSettingsProvider;
let diagnosticsProvider: DiagnosticsProvider;

/**
 * –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 * –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
export function activate(context: vscode.ExtensionContext) {
	console.log('üé§ SpeechToTextWhisper extension is now active!');
	
	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
	extensionContext = context;

	try {
		// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ context variables –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–æ—Ä—è—á–∏–º–∏ –∫–ª–∞–≤–∏—à–∞–º–∏
		initializeContextVariables();
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
		initializeErrorHandling();
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
		initializeComponents();
		
		// –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã
		registerCommands(context);
		
		// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏
		setupKeyBindings(context);
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º WhisperClient –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
		initializeWhisperClient();
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
		showWelcomeMessage();
		
		console.log('‚úÖ SpeechToTextWhisper extension successfully activated');
		
	} catch (error) {
		const errorMessage = `Failed to activate SpeechToTextWhisper: ${(error as Error).message}`;
		console.error(errorMessage);
		vscode.window.showErrorMessage(errorMessage);
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è context variables –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function initializeContextVariables(): void {
	console.log('üîß Initializing context variables...');
	
	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è context variables
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.active', true);
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', false);
	
	// –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–ø–∏—Å–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const recordingMode = config.get<string>('recordingMode', 'hold');
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.recordingMode', recordingMode);
	
	console.log(`‚úÖ Context variables initialized (recordingMode: ${recordingMode})`);
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
 */
function initializeErrorHandling(): void {
	console.log('üîß Initializing error handling system...');
	
	// –°–æ–∑–¥–∞–µ–º ErrorHandler —Å VS Code display handler
	errorHandler = new ErrorHandler(new VSCodeErrorDisplayHandler());
	
	// –°–æ–∑–¥–∞–µ–º RetryManager
	retryManager = new RetryManager(errorHandler);
	
	// –°–æ–∑–¥–∞–µ–º RecoveryActionHandler —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
	const recoveryDependencies: RecoveryDependencies = {
		checkMicrophone: async () => {
			try {
				const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
				if (!ffmpegCheck.available) return false;
				
				const devices = await FFmpegAudioRecorder.detectInputDevices();
				return devices.length > 0;
			} catch (error) {
				return false;
			}
		},
		testApiKey: async () => {
			if (!whisperClient) {
				return false;
			}
			try {
				// –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π blob
				const testBlob = new Blob(['test'], { type: 'audio/wav' });
				await whisperClient.transcribe(testBlob);
				return true;
			} catch (error) {
				// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ - –µ—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ API –∫–ª—é—á–∞, —Ç–æ false
				const errorMessage = (error as Error).message.toLowerCase();
				return !errorMessage.includes('api key') && !errorMessage.includes('unauthorized');
			}
		},
		openSettings: () => {
			vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper');
		},
		reloadExtension: () => {
			vscode.commands.executeCommand('workbench.action.reloadWindow');
		},
		retryLastOperation: async () => {
			// –≠—Ç–æ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
			throw new Error('No operation to retry');
		}
	};
	
	recoveryHandler = new RecoveryActionHandler(recoveryDependencies);
	
	console.log('‚úÖ Error handling system initialized');
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function initializeComponents(): void {
	console.log('üîß Initializing SpeechToTextWhisper components...');
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ContextManager
	initializeContextManager();
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TextInserter
	textInserter = new TextInserter();
	
	// –°–æ–±—ã—Ç–∏—è –¥–ª—è AudioRecorder
	const audioRecorderEvents: AudioRecorderEvents = {
		onRecordingStart: () => {
			console.log('üé§ Recording started');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', true);
			
			statusBarManager.updateRecordingState(true);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –≤ hold-to-record —Ä–µ–∂–∏–º–µ
			if (!isHoldToRecordActive) {
				vscode.window.showInformationMessage('üé§ Recording started...');
			}
		},
		onRecordingStop: async (audioBlob: Blob) => {
			console.log('‚èπÔ∏è Recording stopped');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			
			statusBarManager.updateRecordingState(false);
			await handleTranscription(audioBlob);
		},
		onError: async (error: Error) => {
			console.error('‚ùå Recording error:', error);
			
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', false);
			isHoldToRecordActive = false;
			
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
			const context: ErrorContext = {
				operation: 'audio_recording',
				isHoldToRecordMode: isHoldToRecordActive,
				timestamp: new Date()
			};
			
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
	};

	// –°–æ–±—ã—Ç–∏—è –¥–ª—è StatusBar
	const statusBarEvents: StatusBarEvents = {
		onRecordingToggle: () => {
			// –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–ø–µ—Ä–∞—Ü–∏—é, –Ω–æ –Ω–µ –∂–¥–µ–º –µ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤ —ç—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
			toggleRecording().catch(error => {
				console.error('‚ùå Error in toggleRecording from StatusBar:', error);
				vscode.window.showErrorMessage(`Recording toggle failed: ${error.message}`);
			});
		},
		onSettings: () => {
			openSettings();
		},
		onHelp: () => {
			showHelp();
		}
	};

	// –°–æ–∑–¥–∞–µ–º StatusBarManager —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
	const statusBarConfig: StatusBarConfiguration = {
		position: 'right',
		showTooltips: true,
		enableAnimations: true,
		autoHideOnSuccess: true,
		successDisplayDuration: 2000,
		errorDisplayDuration: 3000
	};
	
	statusBarManager = new StatusBarManager(statusBarEvents, statusBarConfig);
	
	// –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º StatusBarManager —Å ErrorHandler
	errorHandler.setStatusBarManager(statusBarManager);
	
	console.log('‚úÖ Components initialized successfully');
}

/**
 * –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function registerCommands(context: vscode.ExtensionContext): void {
	console.log('üìù Registering commands...');
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–ª—è –±–æ–∫–æ–≤—ã—Ö –ø–∞–Ω–µ–ª–µ–π
	audioSettingsProvider = new AudioSettingsProvider();
	diagnosticsProvider = new DiagnosticsProvider();
	
	// –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–∞–Ω–µ–ª–µ–π
	vscode.window.createTreeView('speechToTextWhisper.audioSettings', {
		treeDataProvider: audioSettingsProvider
	});
	
	vscode.window.createTreeView('speechToTextWhisper.deviceManager', {
		treeDataProvider: audioSettingsProvider
	});
	
	vscode.window.createTreeView('speechToTextWhisper.diagnostics', {
		treeDataProvider: diagnosticsProvider
	});
	
	const commands = [
		// –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∑–∞–ø–∏—Å–∏
		vscode.commands.registerCommand('speechToTextWhisper.startRecording', startRecording),
		vscode.commands.registerCommand('speechToTextWhisper.stopRecording', stopRecording),
		vscode.commands.registerCommand('speechToTextWhisper.toggleRecording', toggleRecording),
		
		// Hold-to-record –∫–æ–º–∞–Ω–¥—ã
		vscode.commands.registerCommand('speechToTextWhisper.startHoldToRecord', startHoldToRecord),
		vscode.commands.registerCommand('speechToTextWhisper.stopHoldToRecord', stopHoldToRecord),
		
		// –ö–æ–º–∞–Ω–¥—ã —Ä–µ–∂–∏–º–æ–≤ –≤—Å—Ç–∞–≤–∫–∏
		vscode.commands.registerCommand('speechToTextWhisper.insertAtCursor', () => insertLastTranscription('cursor')),
		vscode.commands.registerCommand('speechToTextWhisper.insertAsComment', () => insertLastTranscription('comment')),
		vscode.commands.registerCommand('speechToTextWhisper.replaceSelection', () => insertLastTranscription('replace')),
		vscode.commands.registerCommand('speechToTextWhisper.copyToClipboard', () => insertLastTranscription('clipboard')),
		
		// –ö–æ–º–∞–Ω–¥—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
		vscode.commands.registerCommand('speechToTextWhisper.sendToChat', () => insertLastTranscription('chat')),
		vscode.commands.registerCommand('speechToTextWhisper.recordAndSendToChat', async () => {
			await toggleRecording();
			// –ü–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —á–∞—Ç
		}),
		
		// –ö–æ–º–∞–Ω–¥—ã –¥–ª—è –∞—É–¥–∏–æ –ø–∞–Ω–µ–ª–µ–π
		vscode.commands.registerCommand('speechToTextWhisper.audioSettings.refresh', () => audioSettingsProvider.refresh()),
		vscode.commands.registerCommand('speechToTextWhisper.audioSettings.detectDevices', () => audioSettingsProvider.detectDevices()),
		vscode.commands.registerCommand('speechToTextWhisper.audioSettings.selectDevice', (device: AudioDevice) => audioSettingsProvider.selectDevice(device)),
		vscode.commands.registerCommand('speechToTextWhisper.audioSettings.testDevice', (device: AudioDevice) => audioSettingsProvider.testDevice(device)),
		vscode.commands.registerCommand('speechToTextWhisper.audioSettings.openFFmpegSettings', () => audioSettingsProvider.openFFmpegSettings()),
		vscode.commands.registerCommand('speechToTextWhisper.deviceManager.refresh', () => audioSettingsProvider.refresh()),
		vscode.commands.registerCommand('speechToTextWhisper.diagnostics.runAll', () => diagnosticsProvider.runAllDiagnostics()),
		vscode.commands.registerCommand('speechToTextWhisper.diagnostics.refresh', () => diagnosticsProvider.refresh()),
		
		// –£—Ç–∏–ª–∏—Ç–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
		vscode.commands.registerCommand('speechToTextWhisper.openSettings', openSettings),
		vscode.commands.registerCommand('speechToTextWhisper.showHelp', showHelp),
		vscode.commands.registerCommand('speechToTextWhisper.showStatus', showStatus),
		vscode.commands.registerCommand('speechToTextWhisper.checkMicrophone', checkMicrophone),
		vscode.commands.registerCommand('speechToTextWhisper.testApiKey', testApiKey),
		vscode.commands.registerCommand('speechToTextWhisper.showContext', showContextInfo),
		vscode.commands.registerCommand('speechToTextWhisper.refreshContext', refreshContext),
		
		// –ö–æ–º–∞–Ω–¥—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
		vscode.commands.registerCommand('speechToTextWhisper.resetConfiguration', resetConfiguration),
		vscode.commands.registerCommand('speechToTextWhisper.toggleStatusBar', toggleStatusBar),
		
		// –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
		vscode.commands.registerCommand('speechToTextWhisper.runDiagnostics', runDiagnostics)
		
		// TODO: –î–æ–±–∞–≤–∏—Ç—å –∫–æ–º–∞–Ω–¥—ã –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ –ø–æ–∑–∂–µ
		// vscode.commands.registerCommand('speechToTextWhisper.showQualitySettings', showQualitySettings),
		// vscode.commands.registerCommand('speechToTextWhisper.applyQualityPreset', applyQualityPreset),
		// vscode.commands.registerCommand('speechToTextWhisper.optimizeForContext', optimizeForContext),
		// vscode.commands.executeCommand('speechToTextWhisper.exportQualitySettings', exportQualitySettings),
		// vscode.commands.registerCommand('speechToTextWhisper.importQualitySettings', importQualitySettings)
	];

	// –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –≤ –ø–æ–¥–ø–∏—Å–∫–∏
	context.subscriptions.push(...commands, statusBarManager);
	
	console.log(`‚úÖ Registered ${commands.length} commands`);
}

/**
 * –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à –∏ key bindings
 */
function setupKeyBindings(context: vscode.ExtensionContext): void {
	console.log('‚å®Ô∏è Setting up key bindings...');
	
	// –ö–æ–º–∞–Ω–¥—ã startHoldToRecord –∏ stopHoldToRecord —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ registerCommands
	// –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ keybindings –≤ package.json
	// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è keyDown/keyUp –∫–æ–º–∞–Ω–¥ –Ω–µ –Ω—É–∂–Ω–∞
	
	console.log('‚úÖ Key bindings configured (using package.json keybindings)');
}

/**
 * –ö–æ–º–∞–Ω–¥—ã –∑–∞–ø–∏—Å–∏
 */
async function startRecording(): Promise<void> {
	const context: ErrorContext = {
		operation: 'start_recording',
		isHoldToRecordMode: isHoldToRecordActive,
		timestamp: new Date()
	};

	try {
		console.log('‚ñ∂Ô∏è Starting recording...');
		
		// –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é FFmpeg Audio Recorder
		await ensureFFmpegAudioRecorder();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —Å retry
		const microphoneResult = await retryManager.retryMicrophoneOperation(
			async () => {
				const hasPermission = await FFmpegAudioRecorder.checkMicrophonePermission();
				if (hasPermission.state !== 'granted') {
					throw new Error('Microphone permission not granted');
				}
				return hasPermission;
			},
			'microphone_permission_check'
		);

		if (!microphoneResult.success) {
			const error = microphoneResult.lastError || new Error('Microphone access failed');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			return;
		}
		
		if (!audioRecorder) {
			throw new Error('Failed to initialize audio recorder');
		}
		
		await audioRecorder.startRecording();
		
	} catch (error) {
		console.error('‚ùå Failed to start recording:', error);
		
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

function stopRecording(): void {
	const context: ErrorContext = {
		operation: 'stop_recording',
		isHoldToRecordMode: isHoldToRecordActive,
		timestamp: new Date()
	};

	try {
		console.log('‚èπÔ∏è Stopping recording...');
		
		if (!audioRecorder) {
			console.warn('Audio recorder not initialized');
			return;
		}
		
		audioRecorder.stopRecording();
		
	} catch (error) {
		console.error('‚ùå Failed to stop recording:', error);
		
		// –î–ª—è stop recording –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
		errorHandler.handleErrorFromException(error as Error, context);
	}
}

async function toggleRecording(): Promise<void> {
	try {
		// –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é FFmpeg Audio Recorder
		await ensureFFmpegAudioRecorder();
		
		if (!audioRecorder) {
			throw new Error('Failed to initialize audio recorder');
		}
		
		if (audioRecorder.getIsRecording()) {
			stopRecording();
		} else {
			await startRecording();
		}
	} catch (error) {
		console.error('‚ùå Failed to toggle recording:', error);
		vscode.window.showErrorMessage(`Recording toggle failed: ${(error as Error).message}`);
	}
}

/**
 * Hold-to-record —Ñ—É–Ω–∫—Ü–∏–∏ (F9)
 */
async function startHoldToRecord(): Promise<void> {
	if (isHoldToRecordActive) {
		return; // –£–∂–µ –∞–∫—Ç–∏–≤–µ–Ω
	}
	
	console.log('üéØ Starting hold-to-record mode');
	isHoldToRecordActive = true;
	
	// –û–±–Ω–æ–≤–ª—è–µ–º context variable
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', true);
	
	try {
		await startRecording();
	} catch (error) {
		isHoldToRecordActive = false;
		vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', false);
		throw error;
	}
}

function stopHoldToRecord(): void {
	if (!isHoldToRecordActive) {
		return; // –ù–µ –∞–∫—Ç–∏–≤–µ–Ω
	}
	
	console.log('üéØ Stopping hold-to-record mode');
	isHoldToRecordActive = false;
	
	// –û–±–Ω–æ–≤–ª—è–µ–º context variable
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', false);
	
	if (audioRecorder && audioRecorder.getIsRecording()) {
		stopRecording();
	}
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
 */
async function handleTranscription(audioBlob: Blob): Promise<void> {
	const context: ErrorContext = {
		operation: 'transcription',
		isHoldToRecordMode: isHoldToRecordActive,
		timestamp: new Date(),
		additionalData: { audioBlobSize: audioBlob.size }
	};

	try {
		console.log('üîÑ Starting transcription process...');
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		if (!isHoldToRecordActive) {
			vscode.window.showInformationMessage('üîÑ Transcribing audio...');
		}
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
		statusBarManager.showProcessing();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ WhisperClient
		if (!whisperClient) {
			initializeWhisperClient();
			if (!whisperClient) {
				await errorHandler.handleError(ErrorType.API_KEY_MISSING, context);
				return;
			}
		}

		// –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		statusBarManager.showTranscribing();

		// –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
		const config = vscode.workspace.getConfiguration('speechToTextWhisper');
		const language = config.get<string>('language', 'auto');
		const insertMode = config.get<string>('insertMode', 'cursor');
		const prompt = config.get<string>('prompt', '');

		// –û–ø—Ü–∏–∏ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		const transcriptionOptions = {
			language: language === 'auto' ? undefined : language,
			prompt: prompt || undefined,
			temperature: config.get<number>('temperature', 0.1)
		};

		console.log('üéØ Sending audio to Whisper API...');
		
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º retry –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞
		const transcriptionResult = await retryManager.retryApiRequest(
			() => whisperClient.transcribe(audioBlob, transcriptionOptions),
			'whisper_transcription',
			{
				maxAttempts: config.get<number>('maxRetries', 3),
				baseDelay: config.get<number>('retryDelay', 1000)
			}
		);

		if (!transcriptionResult.success) {
			// –ï—Å–ª–∏ retry –Ω–µ –ø–æ–º–æ–≥, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ ErrorHandler
			const error = transcriptionResult.lastError || new Error('Transcription failed after retries');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			return;
		}

		const transcribedText = transcriptionResult.result;
		
		if (transcribedText && transcribedText.trim()) {
			console.log('‚úÖ Transcription successful:', transcribedText.substring(0, 100));
			
			// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
			lastTranscribedText = transcribedText.trim();
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—Å—Ç–∞–≤–∫–∏
			statusBarManager.showInserting();
			
			// –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
			await insertTranscribedTextWithErrorHandling(lastTranscribedText, insertMode, context);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—Ö —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º
			const truncatedText = lastTranscribedText.substring(0, 50) + (lastTranscribedText.length > 50 ? '...' : '');
			statusBarManager.showSuccess(`Inserted: "${truncatedText}"`);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
			if (!isHoldToRecordActive) {
				vscode.window.showInformationMessage(`‚úÖ Transcribed and inserted: "${truncatedText}"`);
			}
			
		} else {
			// –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
			const userAction = await errorHandler.handleError(ErrorType.TRANSCRIPTION_EMPTY, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
		
	} catch (error) {
		console.error('‚ùå Transcription failed:', error);
		
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

/**
 * –í—Å—Ç–∞–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
 */
async function insertTranscribedTextWithErrorHandling(text: string, mode: string, parentContext: ErrorContext): Promise<void> {
	const context: ErrorContext = {
		operation: 'text_insertion',
		isHoldToRecordMode: parentContext.isHoldToRecordMode,
		timestamp: new Date(),
		additionalData: { 
			textLength: text.length,
			insertMode: mode,
			parentOperation: parentContext.operation
		}
	};

	try {
		console.log(`üìù Inserting text in ${mode} mode...`);
		
		const config = vscode.workspace.getConfiguration('speechToTextWhisper');
		const formatText = config.get<boolean>('formatText', true);
		const addNewLine = config.get<boolean>('addNewLine', true);
		const indentToSelection = config.get<boolean>('indentToSelection', false);

		// –ò—Å–ø–æ–ª—å–∑—É–µ–º retry –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—Å—Ç–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞
		const insertResult = await retryManager.retry(
			() => textInserter.insertText(text, {
				mode: mode as 'cursor' | 'comment' | 'replace' | 'newLine' | 'clipboard',
				formatText,
				addNewLine,
				indentToSelection
			}),
			'text_insertion',
			{ maxAttempts: 2, strategy: 'fixed_delay' as any, baseDelay: 500 }
		);

		if (!insertResult.success) {
			const error = insertResult.lastError || new Error('Text insertion failed after retries');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			throw error;
		}
		
		console.log('‚úÖ Text inserted successfully');
		
	} catch (error) {
		console.error('‚ùå Text insertion failed:', error);
		
		// –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ ErrorHandler –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
		if (!(error as any).handled) {
			const userAction = await errorHandler.handleErrorFromException(error as Error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
		
		throw error; // –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã—à–µ
	}
}

/**
 * –ö–æ–º–∞–Ω–¥—ã —Ä–µ–∂–∏–º–æ–≤ –≤—Å—Ç–∞–≤–∫–∏
 */
async function insertLastTranscription(mode: string): Promise<void> {
	if (!lastTranscribedText) {
		vscode.window.showWarningMessage('No transcribed text available. Please record something first.');
		return;
	}
	
	try {
		await insertTranscribedTextWithErrorHandling(lastTranscribedText, mode, {
			operation: 'text_insertion',
			isHoldToRecordMode: isHoldToRecordActive,
			timestamp: new Date(),
			additionalData: { 
				textLength: lastTranscribedText.length,
				insertMode: mode,
				parentOperation: 'transcription'
			}
		});
		vscode.window.showInformationMessage(`Text inserted in ${mode} mode`);
	} catch (error) {
		// –û—à–∏–±–∫–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤ insertTranscribedTextWithErrorHandling
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperClient
 */
function initializeWhisperClient(): void {
	console.log('üîß Initializing Whisper client...');
	
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const apiKey = config.get<string>('apiKey');

	if (!apiKey) {
		console.warn('‚ö†Ô∏è OpenAI API key not configured');
		statusBarManager.showWarning('API key not configured');
		return;
	}

	if (!WhisperClient.validateApiKey(apiKey)) {
		console.error('‚ùå Invalid OpenAI API key format');
		statusBarManager.showError('Invalid API key format', 'critical');
		return;
	}

	try {
		whisperClient = new WhisperClient({
			apiKey,
			timeout: config.get<number>('timeout', 30000),
			maxRetries: config.get<number>('maxRetries', 3),
			retryDelay: config.get<number>('retryDelay', 1000),
			baseURL: config.get<string>('baseURL') || undefined
		});
		
		console.log('‚úÖ Whisper client initialized successfully');
		
	} catch (error) {
		const errorMessage = `Failed to initialize Whisper client: ${(error as Error).message}`;
		console.error(errorMessage);
		statusBarManager.showError(errorMessage, 'critical');
	}
}

/**
 * –£—Ç–∏–ª–∏—Ç–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
 */
function openSettings(): void {
	vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper');
}

function showHelp(): void {
	const helpText = `
üé§ **SpeechToTextWhisper Help**

**Recording:**
‚Ä¢ F9 (hold): Hold to record, release to stop
‚Ä¢ Toggle recording: Ctrl+Shift+V (or use command palette)

**Commands:**
‚Ä¢ Voice Scribe: Start Recording
‚Ä¢ Voice Scribe: Stop Recording  
‚Ä¢ Voice Scribe: Toggle Recording
‚Ä¢ Voice Scribe: Insert as Comment
‚Ä¢ Voice Scribe: Replace Selection

**Settings:**
‚Ä¢ OpenAI API Key (required)
‚Ä¢ Language (auto-detect or specific)
‚Ä¢ Insert Mode (cursor/comment/replace)
‚Ä¢ Audio Quality settings

**Troubleshooting:**
‚Ä¢ Check microphone permissions
‚Ä¢ Verify API key is valid
‚Ä¢ Test microphone access
`;

	vscode.window.showInformationMessage(helpText, { modal: true });
}

function showStatus(): void {
	const status = statusBarManager.getStatus();
	const context = textInserter.getActiveContext();
	
	const statusText = `
**SpeechToTextWhisper Status:**

üé§ Recording: ${status.isRecording ? 'Active' : 'Inactive'}
üìä State: ${status.state}
üîß API Client: ${whisperClient ? 'Ready' : 'Not configured'}
üìù Context: ${context.type} (${context.language || 'unknown'})
üíæ Last Error: ${status.lastError || 'None'}
üìã Last Transcription: ${lastTranscribedText ? 'Available' : 'None'}
`;

	vscode.window.showInformationMessage(statusText, { modal: true });
}

function showContextInfo(): void {
	if (!contextManager) {
		vscode.window.showWarningMessage('ContextManager not initialized');
		return;
	}
	
	const context = contextManager.getContext();
	const language = contextManager.getCurrentLanguage();
	
	const contextText = `
**SpeechToTextWhisper Context Information:**

üîç **IDE Type:** ${context.ideType}
üìç **Current Context:** ${context.contextType}

${context.activeEditor ? `üìù **Active Editor:**
‚Ä¢ File: ${context.activeEditor.fileName}
‚Ä¢ Language: ${context.activeEditor.language.name} (${context.activeEditor.language.id})
‚Ä¢ Position: Line ${context.activeEditor.lineNumber}, Column ${context.activeEditor.columnNumber}
‚Ä¢ Comment Style: ${context.activeEditor.language.commentStyle}
${context.activeEditor.language.lineComment ? `‚Ä¢ Line Comment: ${context.activeEditor.language.lineComment}` : ''}
${context.activeEditor.language.blockComment ? `‚Ä¢ Block Comment: ${context.activeEditor.language.blockComment.start} ... ${context.activeEditor.language.blockComment.end}` : ''}
` : ''}

${context.terminal?.isActive ? `üíª **Terminal:** ${context.terminal.name}\n` : ''}

${context.debugger?.isActive ? `üêõ **Debugger:** ${context.debugger.sessionName || 'Active'}\n` : ''}

${context.workspace ? `üìÅ **Workspace:** ${context.workspace.name}
‚Ä¢ Folders: ${context.workspace.folders.length} folder(s)
` : ''}

**Comment Support:**
‚Ä¢ Line Comments: ${language ? contextManager.supportsComments('line') : 'N/A'}
‚Ä¢ Block Comments: ${language ? contextManager.supportsComments('block') : 'N/A'}
‚Ä¢ Preferred Style: ${contextManager.getPreferredCommentStyle() || 'N/A'}
`;

	vscode.window.showInformationMessage(contextText, { modal: true });
}

function refreshContext(): void {
	if (!contextManager) {
		vscode.window.showWarningMessage('ContextManager not initialized');
		return;
	}
	
	try {
		contextManager.refreshContext();
		const context = contextManager.getContext();
		vscode.window.showInformationMessage(
			`üîÑ Context refreshed: ${context.contextType} in ${context.ideType}`
		);
	} catch (error) {
		const errorMessage = (error as Error).message;
		vscode.window.showErrorMessage(`‚ùå Failed to refresh context: ${errorMessage}`);
	}
}

async function checkMicrophone(): Promise<void> {
	try {
		statusBarManager.showProcessing();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å FFmpeg
		const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
		if (!ffmpegCheck.available) {
			throw new Error(`FFmpeg not available: ${ffmpegCheck.error || 'Not found in PATH'}`);
		}
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
		const devices = await FFmpegAudioRecorder.detectInputDevices();
		if (devices.length === 0) {
			throw new Error('No audio input devices found');
		}
		
		statusBarManager.showSuccess('Microphone ready');
		vscode.window.showInformationMessage(`‚úÖ Microphone is working correctly. Found ${devices.length} audio device(s).`);
		
	} catch (error) {
		const errorMessage = (error as Error).message;
		statusBarManager.showError(errorMessage, 'error');
		vscode.window.showErrorMessage(`‚ùå ${errorMessage}`);
	}
}

async function testApiKey(): Promise<void> {
	if (!whisperClient) {
		vscode.window.showWarningMessage('Please configure your OpenAI API key first');
		return;
	}
	
	try {
		statusBarManager.showProcessing();
		
		// –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ blob (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π WAV —Ñ–∞–π–ª)
		const testBlob = new Blob(['test'], { type: 'audio/wav' });
		
		try {
			await whisperClient.transcribe(testBlob);
			statusBarManager.showSuccess('API key validated');
			vscode.window.showInformationMessage('‚úÖ OpenAI API key is working correctly');
		} catch (error) {
			// –û–∂–∏–¥–∞–µ–º–∞—è –æ—à–∏–±–∫–∞ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –Ω–æ API key –≤–∞–ª–∏–¥–µ–Ω –µ—Å–ª–∏ –º—ã –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç –æ—Ç API
			const errorMessage = (error as Error).message;
			if (errorMessage.includes('audio') || errorMessage.includes('format')) {
				statusBarManager.showSuccess('API key validated');
				vscode.window.showInformationMessage('‚úÖ OpenAI API key is working correctly');
			} else {
				throw error;
			}
		}
		
	} catch (error) {
		const errorMessage = (error as Error).message;
		statusBarManager.showError(errorMessage, 'critical');
		vscode.window.showErrorMessage(`‚ùå API key test failed: ${errorMessage}`);
	}
}

function resetConfiguration(): void {
	vscode.window.showWarningMessage(
		'This will reset all SpeechToTextWhisper settings to defaults. Continue?',
		'Yes', 'No'
	).then(selection => {
		if (selection === 'Yes') {
			const config = vscode.workspace.getConfiguration('speechToTextWhisper');
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∫—Ä–æ–º–µ API –∫–ª—é—á–∞)
			config.update('language', 'auto', vscode.ConfigurationTarget.Global);
			config.update('insertMode', 'cursor', vscode.ConfigurationTarget.Global);
			config.update('formatText', true, vscode.ConfigurationTarget.Global);
			
			vscode.window.showInformationMessage('‚úÖ Configuration reset to defaults');
		}
	});
}

function toggleStatusBar(): void {
	const status = statusBarManager.getStatus();
	if (status.isVisible) {
		statusBarManager.hide();
		vscode.window.showInformationMessage('Status bar hidden');
	} else {
		statusBarManager.show();
		vscode.window.showInformationMessage('Status bar shown');
	}
}

/**
 * –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
 */
function showWelcomeMessage(): void {
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const hasApiKey = config.get<string>('apiKey');
	
	if (!hasApiKey) {
		vscode.window.showInformationMessage(
			'üé§ Welcome to SpeechToTextWhisper! Please configure your OpenAI API key to get started.',
			'Open Settings'
		).then(selection => {
			if (selection === 'Open Settings') {
				openSettings();
			}
		});
	}
}

/**
 * –§—É–Ω–∫—Ü–∏—è –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 * –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
export function deactivate() {
	console.log('üîå Deactivating SpeechToTextWhisper extension...');
	
	try {
		// –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –∞–∫—Ç–∏–≤–Ω–∞
		if (audioRecorder && audioRecorder.getIsRecording()) {
			console.log('‚èπÔ∏è Stopping active recording...');
			audioRecorder.stopRecording();
		}
		
		// –û—á–∏—â–∞–µ–º hold-to-record —Å–æ—Å—Ç–æ—è–Ω–∏–µ
		if (isHoldToRecordActive) {
			isHoldToRecordActive = false;
		}
		
		// –û—á–∏—â–∞–µ–º –¥–∏—Å–ø–æ–∑–∞–±–ª—ã
		if (holdToRecordDisposable) {
			holdToRecordDisposable.dispose();
		}
		
		// –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã ContextManager
		if (contextManager) {
			console.log('üîå Disposing ContextManager...');
			contextManager.dispose();
		}
		
		console.log('‚úÖ SpeechToTextWhisper extension deactivated successfully');
		
	} catch (error) {
		console.error('‚ùå Error during deactivation:', error);
	}
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
 */
async function handleUserRecoveryAction(userAction: string, context: ErrorContext): Promise<void> {
	console.log(`üîß Handling user recovery action: ${userAction}`);
	
	try {
		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞
		if (userAction === 'Open Settings') {
			await recoveryHandler.executeRecoveryAction('open_settings' as any);
		} else if (userAction === 'Check Microphone') {
			await recoveryHandler.executeRecoveryAction('enable_microphone' as any);
		} else if (userAction === 'Retry') {
			await recoveryHandler.executeRecoveryAction('retry' as any);
		} else if (userAction === 'Check Network') {
			await recoveryHandler.executeRecoveryAction('check_network' as any);
		} else if (userAction === 'Reload Extension') {
			await recoveryHandler.executeRecoveryAction('refresh_extension' as any);
		}
	} catch (error) {
		console.error('‚ùå Recovery action failed:', error);
		vscode.window.showErrorMessage(`Recovery action failed: ${(error as Error).message}`);
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ContextManager
 */
function initializeContextManager(): void {
	console.log('üîß Initializing ContextManager...');
	
	const contextEvents: ContextManagerEvents = {
		onContextChange: (context: IDEContext) => {
			console.log(`üîÑ Context changed: ${context.contextType} in ${context.ideType}`);
			
			// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
			adaptToContext(context);
		},
		
		onIDETypeDetected: (ideType: IDEType) => {
			console.log(`üîç IDE detected: ${ideType}`);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è IDE —Å–æ–æ–±—â–µ–Ω–∏—è
			if (ideType === IDEType.CURSOR) {
				console.log('üéØ Cursor IDE detected - AI chat integration available');
			} else if (ideType === IDEType.VSCODE) {
				console.log('üí° VS Code detected - standard functionality enabled');
			}
		},
		
		onLanguageChange: (language) => {
			console.log(`üìù Language changed: ${language.name} (${language.id})`);
			
			// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ–¥ —è–∑—ã–∫
			if (textInserter) {
				// TextInserter —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç VS Code API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞
				// –Ω–æ —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∏–ª–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
			}
		}
	};
	
	contextManager = new ContextManager(contextEvents);
	
	console.log('‚úÖ ContextManager initialized successfully');
}

/**
 * –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∫ —Ç–µ–∫—É—â–µ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
 */
function adaptToContext(context: IDEContext): void {
	try {
		// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ StatusBar –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
		if (statusBarManager) {
			// –í —Ä–µ–∂–∏–º–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ –∏–ª–∏ –æ—Ç–ª–∞–¥—á–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
			if (context.contextType === ContextType.TERMINAL || context.contextType === ContextType.DEBUGGER) {
				// StatusBarManager —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –Ω–æ –º–æ–∂–µ–º –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å tooltip
			}
		}
		
		// –î–ª—è Cursor - –≥–æ—Ç–æ–≤–∏–º—Å—è –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —á–∞—Ç–æ–º
		if (context.ideType === IDEType.CURSOR && context.contextType === ContextType.CHAT) {
			console.log('üí¨ Cursor chat context detected - ready for AI chat integration');
		}
		
		// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–µ–∂–∏–º –≤—Å—Ç–∞–≤–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
		if (context.activeEditor) {
			const language = context.activeEditor.language;
			console.log(`üìù Active file: ${language.name}, supports comments: line=${contextManager.supportsComments('line')}, block=${contextManager.supportsComments('block')}`);
		}
		
	} catch (error) {
		console.error('‚ùå Error adapting to context:', error);
	}
}

/**
 * –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
async function runDiagnostics(): Promise<void> {
	console.log('üîß Running SpeechToTextWhisper diagnostics...');
	
	const diagnosticsResults: string[] = [];
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
	diagnosticsResults.push('‚úÖ Extension activated');
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const apiKey = config.get<string>('apiKey');
	if (apiKey && apiKey.trim()) {
		diagnosticsResults.push('‚úÖ API key configured');
	} else {
		diagnosticsResults.push('‚ùå API key missing');
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É FFmpeg
	const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
	if (ffmpegCheck.available) {
		diagnosticsResults.push('‚úÖ FFmpeg available');
		if (ffmpegCheck.version) {
			diagnosticsResults.push(`üì¶ FFmpeg version: ${ffmpegCheck.version}`);
		}
	} else {
		diagnosticsResults.push(`‚ùå FFmpeg not available: ${ffmpegCheck.error || 'Not found'}`);
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
	try {
		const devices = await FFmpegAudioRecorder.detectInputDevices();
		if (devices.length > 0) {
			diagnosticsResults.push(`‚úÖ Audio devices found: ${devices.length}`);
			devices.slice(0, 3).forEach(device => {
				diagnosticsResults.push(`  üì± ${device}`);
			});
		} else {
			diagnosticsResults.push('‚ùå No audio input devices found');
		}
	} catch (error) {
		diagnosticsResults.push(`‚ùå Audio device check failed: ${(error as Error).message}`);
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
	diagnosticsResults.push(`üìä Recording state: ${audioRecorder?.getIsRecording() ? 'active' : 'inactive'}`);
	diagnosticsResults.push(`üìä Hold-to-record: ${isHoldToRecordActive ? 'active' : 'inactive'}`);
	diagnosticsResults.push(`üìä Last transcription: ${lastTranscribedText ? 'available' : 'none'}`);
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
	const recordingMode = config.get<string>('recordingMode', 'hold');
	const language = config.get<string>('language', 'auto');
	const insertMode = config.get<string>('insertMode', 'cursor');
	
	diagnosticsResults.push(`‚öôÔ∏è Recording mode: ${recordingMode}`);
	diagnosticsResults.push(`‚öôÔ∏è Language: ${language}`);
	diagnosticsResults.push(`‚öôÔ∏è Insert mode: ${insertMode}`);
	
	// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
	const message = 'SpeechToTextWhisper Diagnostics:\n\n' + diagnosticsResults.join('\n');
	
	vscode.window.showInformationMessage(message, 'Copy to Clipboard', 'OK').then(selection => {
		if (selection === 'Copy to Clipboard') {
			vscode.env.clipboard.writeText(message);
			vscode.window.showInformationMessage('Diagnostics copied to clipboard');
		}
	});
	
	console.log('Diagnostics results:', diagnosticsResults);
}

/**
 * –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FFmpeg Audio Recorder
 */
async function ensureFFmpegAudioRecorder(): Promise<void> {
	if (audioRecorder) return;

	console.log('üîß Initializing FFmpeg audio recorder...');

	// –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ FFmpeg
	const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
	if (!ffmpegCheck.available) {
		const error = new Error('FFmpeg not found. Please install FFmpeg and add it to PATH.');
		
		// –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ
		const action = await vscode.window.showErrorMessage(
			'FFmpeg is required for audio recording but was not found.',
			'Install Guide', 'Settings'
		);
		
		if (action === 'Install Guide') {
			vscode.env.openExternal(vscode.Uri.parse('https://ffmpeg.org/download.html'));
		} else if (action === 'Settings') {
			vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper.ffmpegPath');
		}
		
		throw error;
	}

	// –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	
	// –ü–æ–ª—É—á–∞–µ–º inputDevice –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
	const inputDeviceSetting = config.get<string>('inputDevice');
	const inputDevice = inputDeviceSetting === 'auto' || !inputDeviceSetting ? undefined : inputDeviceSetting;
	
	// –°–æ–±—ã—Ç–∏—è –¥–ª—è AudioRecorder
	const audioRecorderEvents: AudioRecorderEvents = {
		onRecordingStart: () => {
			console.log('üé§ Recording started');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', true);
			
			statusBarManager.updateRecordingState(true);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –≤ hold-to-record —Ä–µ–∂–∏–º–µ
			if (!isHoldToRecordActive) {
				vscode.window.showInformationMessage('üé§ Recording started...');
			}
		},
		onRecordingStop: async (audioBlob: Blob) => {
			console.log('‚èπÔ∏è Recording stopped');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			
			statusBarManager.updateRecordingState(false);
			await handleTranscription(audioBlob);
		},
		onError: async (error: Error) => {
			console.error('‚ùå Recording error:', error);
			
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.holdToRecordActive', false);
			isHoldToRecordActive = false;
			
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
			const context: ErrorContext = {
				operation: 'audio_recording',
				isHoldToRecordMode: isHoldToRecordActive,
				timestamp: new Date()
			};
			
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
	};
	
	audioRecorder = new FFmpegAudioRecorder(audioRecorderEvents, {
		sampleRate: config.get<number>('sampleRate', 16000),
		channelCount: config.get<number>('channels', 1),
		audioFormat: config.get<'wav' | 'mp3' | 'webm' | 'opus'>('audioFormat', 'wav'),
		codec: config.get<string>('audioCodec', 'pcm_s16le'),
		inputDevice: inputDevice,
		ffmpegPath: config.get<string>('ffmpegPath') || undefined,
		maxDuration: config.get<number>('maxRecordingDuration', 60)
	});
	
	console.log('‚úÖ FFmpeg audio recorder initialized');
}
