// The module 'vscode' contains the VS Code extensibility API
// Import the module and reference it with the alias vscode in your code below
import * as vscode from 'vscode';
import { FFmpegAudioRecorder, AudioRecorderEvents } from './core/FFmpegAudioRecorder';
import { WhisperClient } from './core/WhisperClient';
import { TextInserter } from './ui/TextInserter';
import { StatusBarManager, StatusBarEvents, StatusBarConfiguration } from './ui/StatusBarManager';
import { AudioSettingsProvider } from './ui/AudioSettingsProvider';
import { DiagnosticsProvider, DeviceManagerProvider } from './ui/DiagnosticsProvider';
import { ErrorHandler, ErrorType, ErrorContext, VSCodeErrorDisplayHandler } from './utils/ErrorHandler';
import { RetryManager } from './utils/RetryManager';
import { RecoveryActionHandler, RecoveryDependencies } from './utils/RecoveryActionHandler';
import { ContextManager, IDEType, ContextType, IDEContext, ContextManagerEvents } from './core/ContextManager';
import { CursorIntegration, CursorIntegrationStrategy } from './integrations/CursorIntegration';

// –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
let audioRecorder: FFmpegAudioRecorder | null = null;
let whisperClient: WhisperClient;
let textInserter: TextInserter;
let statusBarManager: StatusBarManager;

// –°–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
let errorHandler: ErrorHandler;
let retryManager: RetryManager;
let recoveryHandler: RecoveryActionHandler;

// –ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ IDE
let contextManager: ContextManager;

// –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
let extensionContext: vscode.ExtensionContext;

// –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
let lastTranscribedText: string | null = null;

// –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —á–∞—Å—Ç—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
let lastRecordingStartTime = 0;
const MIN_RECORDING_INTERVAL = 200; // –º–∏–Ω–∏–º—É–º 200ms –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

// –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —Å–ø–∞–º–∞ –æ—à–∏–±–æ–∫
let lastErrorTime = 0;
let lastErrorMessage = '';
const MIN_ERROR_INTERVAL = 3000; // –º–∏–Ω–∏–º—É–º 3 —Å–µ–∫—É–Ω–¥—ã –º–µ–∂–¥—É –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –æ—à–∏–±–∫–∞–º–∏

// –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —Ä–µ–∂–∏–º–∞ –∑–∞–ø–∏—Å–∏
let currentRecordingMode: 'chat' | 'clipboard' | null = null;

// UI –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–ª—è –±–æ–∫–æ–≤—ã—Ö –ø–∞–Ω–µ–ª–µ–π
let audioSettingsProvider: AudioSettingsProvider;
let deviceManagerProvider: DeviceManagerProvider;
let diagnosticsProvider: DiagnosticsProvider;

// –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Cursor —á–∞—Ç–æ–º
let cursorIntegration: CursorIntegration;

/**
 * –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 * –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
export function activate(context: vscode.ExtensionContext) {
	console.log('üé§ SpeechToTextWhisper extension is now active!');
	
	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
	extensionContext = context;

	try {
		// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ context variables –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≥–æ—Ä—è—á–∏–º–∏ –∫–ª–∞–≤–∏—à–∞–º–∏
		initializeContextVariables();
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
		initializeErrorHandling();
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
		initializeComponents();
		
		// –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã
		registerCommands(context);
		
		// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏
		setupKeyBindings(context);
		
		// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º WhisperClient –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏
		initializeWhisperClient();
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
		showWelcomeMessage();
		
		console.log('‚úÖ SpeechToTextWhisper extension successfully activated');
		
	} catch (error) {
		const errorMessage = `Failed to activate SpeechToTextWhisper: ${(error as Error).message}`;
		console.error(errorMessage);
		vscode.window.showErrorMessage(errorMessage);
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è context variables –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function initializeContextVariables(): void {
	console.log('üîß Initializing context variables...');
	
	// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è context variables
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.active', true);
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
	
	// –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–ø–∏—Å–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const recordingMode = config.get<string>('recordingMode', 'chat');
	vscode.commands.executeCommand('setContext', 'speechToTextWhisper.recordingMode', recordingMode);
	
	console.log(`‚úÖ Context variables initialized (recordingMode: ${recordingMode})`);
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
 */
function initializeErrorHandling(): void {
	console.log('üîß Initializing error handling system...');
	
	// –°–æ–∑–¥–∞–µ–º ErrorHandler —Å VS Code display handler
	errorHandler = new ErrorHandler(new VSCodeErrorDisplayHandler());
	
	// –°–æ–∑–¥–∞–µ–º RetryManager
	retryManager = new RetryManager(errorHandler);
	
	// –°–æ–∑–¥–∞–µ–º RecoveryActionHandler —Å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏
	const recoveryDependencies: RecoveryDependencies = {
		checkMicrophone: async () => {
			try {
				const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
				if (!ffmpegCheck.available) return false;
				
				const devices = await FFmpegAudioRecorder.detectInputDevices();
				return devices.length > 0;
			} catch (error) {
				return false;
			}
		},
		testApiKey: async () => {
			if (!whisperClient) {
				return false;
			}
			try {
				// –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π blob
				const testBlob = new Blob(['test'], { type: 'audio/wav' });
				await whisperClient.transcribe(testBlob);
				return true;
			} catch (error) {
				// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ - –µ—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ API –∫–ª—é—á–∞, —Ç–æ false
				const errorMessage = (error as Error).message.toLowerCase();
				return !errorMessage.includes('api key') && !errorMessage.includes('unauthorized');
			}
		},
		openSettings: () => {
			vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper');
		},
		reloadExtension: () => {
			vscode.commands.executeCommand('workbench.action.reloadWindow');
		},
		retryLastOperation: async () => {
			// –≠—Ç–æ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö
			throw new Error('No operation to retry');
		}
	};
	
	recoveryHandler = new RecoveryActionHandler(recoveryDependencies);
	
	console.log('‚úÖ Error handling system initialized');
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function initializeComponents(): void {
	console.log('üîß Initializing SpeechToTextWhisper components...');
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ContextManager
	initializeContextManager();
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º CursorIntegration
	initializeCursorIntegration();
	
	// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º TextInserter
	textInserter = new TextInserter();
	
	// –°–æ–±—ã—Ç–∏—è –¥–ª—è AudioRecorder
	const audioRecorderEvents: AudioRecorderEvents = {
		onRecordingStart: () => {
			console.log('üé§ Recording started');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', true);
			
			statusBarManager.updateRecordingState(true);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
			vscode.window.showInformationMessage('üé§ Recording started...');
		},
		onRecordingStop: async (audioBlob: Blob) => {
			console.log('‚èπÔ∏è Recording stopped');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			
			statusBarManager.updateRecordingState(false);
			await handleTranscription(audioBlob);
		},
		onError: async (error: Error) => {
			console.error('‚ùå Recording error:', error);
			
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			currentRecordingMode = null;
			
			// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫—É
			const errorMessage = error.message;
			if (!shouldShowError(errorMessage)) {
				return; // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –æ—à–∏–±–∫–∏
			}
			
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
			const context: ErrorContext = {
				operation: 'audio_recording',
				isHoldToRecordMode: false,
				timestamp: new Date()
			};
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ —á–µ—Ä–µ–∑ ErrorHandler
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
	};

	// –°–æ–±—ã—Ç–∏—è –¥–ª—è StatusBar
	const statusBarEvents: StatusBarEvents = {
		onRecordingToggle: () => {
			// –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–∞–Ω–¥—É –∑–∞–ø–∏—Å–∏ –≤ —á–∞—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
			recordAndSendToChat().catch(error => {
				console.error('‚ùå Error in recordAndSendToChat from StatusBar:', error);
				vscode.window.showErrorMessage(`Recording failed: ${error.message}`);
			});
		},
		onSettings: () => {
			openSettings();
		},
		onHelp: () => {
			showHelp();
		}
	};

	// –°–æ–∑–¥–∞–µ–º StatusBarManager —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
	const statusBarConfig: StatusBarConfiguration = {
		position: 'right',
		showTooltips: true,
		enableAnimations: true,
		autoHideOnSuccess: true,
		successDisplayDuration: 2000,
		errorDisplayDuration: 3000
	};
	
	statusBarManager = new StatusBarManager(statusBarEvents, statusBarConfig);
	
	// –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º StatusBarManager —Å ErrorHandler
	errorHandler.setStatusBarManager(statusBarManager);
	
	console.log('‚úÖ Components initialized successfully');
}

/**
 * –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–∞–Ω–¥ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
function registerCommands(context: vscode.ExtensionContext): void {
	console.log('üìù Registering commands...');
	
	const commands = [
		// –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∑–∞–ø–∏—Å–∏
		vscode.commands.registerCommand('speechToTextWhisper.recordAndSendToChat', recordAndSendToChat),
		vscode.commands.registerCommand('speechToTextWhisper.recordToClipboard', recordToClipboard),
		
		// –°–ª—É–∂–µ–±–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
		vscode.commands.registerCommand('speechToTextWhisper.openSettings', openSettings),
		vscode.commands.registerCommand('speechToTextWhisper.runDiagnostics', runDiagnostics)
	];

	// –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–æ–º–∞–Ω–¥—ã –≤ –ø–æ–¥–ø–∏—Å–∫–∏
	context.subscriptions.push(...commands, statusBarManager);
	
	console.log(`‚úÖ Registered ${commands.length} commands`);
}

/**
 * –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–æ—Ä—è—á–∏—Ö –∫–ª–∞–≤–∏—à –∏ key bindings
 */
function setupKeyBindings(context: vscode.ExtensionContext): void {
	console.log('‚å®Ô∏è Setting up key bindings...');
	
	// –ö–æ–º–∞–Ω–¥—ã startHoldToRecord –∏ stopHoldToRecord —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã –≤ registerCommands
	// –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ keybindings –≤ package.json
	// –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è keyDown/keyUp –∫–æ–º–∞–Ω–¥ –Ω–µ –Ω—É–∂–Ω–∞
	
	console.log('‚úÖ Key bindings configured (using package.json keybindings)');
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
 */
async function handleTranscription(audioBlob: Blob): Promise<void> {
	const context: ErrorContext = {
		operation: 'transcription',
		isHoldToRecordMode: false,
		timestamp: new Date(),
		additionalData: { audioBlobSize: audioBlob.size }
	};

	try {
		console.log('üîÑ Starting transcription process...');
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		if (!currentRecordingMode) {
			vscode.window.showInformationMessage('üîÑ Transcribing audio...');
		}
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
		statusBarManager.showProcessing();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ WhisperClient
		if (!whisperClient) {
			initializeWhisperClient();
			if (!whisperClient) {
				await errorHandler.handleError(ErrorType.API_KEY_MISSING, context);
				return;
			}
		}

		// –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		statusBarManager.showTranscribing();

		// –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
		const config = vscode.workspace.getConfiguration('speechToTextWhisper');
		const language = config.get<string>('language', 'auto');
		const insertMode = config.get<string>('insertMode', 'cursor');
		const prompt = config.get<string>('prompt', '');

		// –û–ø—Ü–∏–∏ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
		const transcriptionOptions = {
			language: language === 'auto' ? undefined : language,
			prompt: prompt || undefined,
			temperature: config.get<number>('temperature', 0.1)
		};

		console.log('üéØ Sending audio to Whisper API...');
		
		// –ò—Å–ø–æ–ª—å–∑—É–µ–º retry –¥–ª—è API –∑–∞–ø—Ä–æ—Å–∞
		const transcriptionResult = await retryManager.retryApiRequest(
			() => whisperClient.transcribe(audioBlob, transcriptionOptions),
			'whisper_transcription',
			{
				maxAttempts: config.get<number>('maxRetries', 3),
				baseDelay: config.get<number>('retryDelay', 1000)
			}
		);

		if (!transcriptionResult.success) {
			// –ï—Å–ª–∏ retry –Ω–µ –ø–æ–º–æ–≥, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ ErrorHandler
			const error = transcriptionResult.lastError || new Error('Transcription failed after retries');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			return;
		}

		const transcribedText = transcriptionResult.result;
		
		if (transcribedText && transcribedText.trim()) {
			console.log('‚úÖ Transcription successful:', transcribedText.substring(0, 100));
			
			// –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é
			lastTranscribedText = transcribedText.trim();
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤—Å—Ç–∞–≤–∫–∏
			statusBarManager.showInserting();
			
			// üéØ –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –ò—Å–ø–æ–ª—å–∑—É–µ–º currentRecordingMode –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–µ–π—Å—Ç–≤–∏—è
			console.log(`üîç Current recording mode: ${currentRecordingMode}`);
			
			if (currentRecordingMode === 'chat') {
				console.log('üéØ Sending to Cursor chat (mode: chat)');
				
				try {
					// –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ —á–∞—Ç —á–µ—Ä–µ–∑ CursorIntegration
					await insertLastTranscription('chat');
					
					// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—Ö
					const truncatedText = lastTranscribedText.substring(0, 50) + (lastTranscribedText.length > 50 ? '...' : '');
					statusBarManager.showSuccess(`Sent to chat: "${truncatedText}"`);
					
					// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
					vscode.window.showInformationMessage(`‚úÖ Transcribed and sent to chat: "${truncatedText}"`);
					
					// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º
					currentRecordingMode = null;
					return; // –ó–∞–≤–µ—Ä—à–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
					
				} catch (error) {
					console.error('‚ùå Failed to send to chat:', error);
					vscode.window.showErrorMessage(`Failed to send to chat: ${(error as Error).message}`);
					// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –∏ –∑–∞–≤–µ—Ä—à–∞–µ–º
					currentRecordingMode = null;
					return;
				}
			} else if (currentRecordingMode === 'clipboard') {
				console.log('üìã Copying to clipboard (mode: clipboard)');
				
				try {
					// –ö–æ–ø–∏—Ä—É–µ–º –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞
					await insertLastTranscription('clipboard');
					
					// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—Ö
					const truncatedText = lastTranscribedText.substring(0, 50) + (lastTranscribedText.length > 50 ? '...' : '');
					statusBarManager.showSuccess(`Copied: "${truncatedText}"`);
					
					// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
					vscode.window.showInformationMessage(`‚úÖ Transcribed and copied to clipboard: "${truncatedText}"`);
					
					// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º
					currentRecordingMode = null;
					return; // –ó–∞–≤–µ—Ä—à–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é
					
				} catch (error) {
					console.error('‚ùå Failed to copy to clipboard:', error);
					vscode.window.showErrorMessage(`Failed to copy to clipboard: ${(error as Error).message}`);
					// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –∏ –∑–∞–≤–µ—Ä—à–∞–µ–º
					currentRecordingMode = null;
					return;
				}
			}
			
			// –ï—Å–ª–∏ —Ä–µ–∂–∏–º –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
			console.log('üìù Using default insert mode (no specific recording mode set)');
			
			// –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –≤ —Ä–µ–¥–∞–∫—Ç–æ—Ä (–æ–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞)
			const insertMode = config.get<string>('insertMode', 'cursor');
			await insertTranscribedTextWithErrorHandling(lastTranscribedText, insertMode, context);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Å–ø–µ—Ö —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º
			const truncatedText = lastTranscribedText.substring(0, 50) + (lastTranscribedText.length > 50 ? '...' : '');
			statusBarManager.showSuccess(`Inserted: "${truncatedText}"`);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
			vscode.window.showInformationMessage(`‚úÖ Transcribed and inserted: "${truncatedText}"`);
			
		} else {
			// –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
			const userAction = await errorHandler.handleError(ErrorType.TRANSCRIPTION_EMPTY, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
		
	} catch (error) {
		console.error('‚ùå Transcription failed:', error);
		
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

/**
 * –í—Å—Ç–∞–≤–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
 */
async function insertTranscribedTextWithErrorHandling(text: string, mode: string, parentContext: ErrorContext): Promise<void> {
	const context: ErrorContext = {
		operation: 'text_insertion',
		isHoldToRecordMode: false,
		timestamp: new Date(),
		additionalData: { 
			textLength: text.length,
			insertMode: mode,
			parentOperation: parentContext.operation
		}
	};

	try {
		console.log(`üìù Inserting text in ${mode} mode...`);
		
		const config = vscode.workspace.getConfiguration('speechToTextWhisper');
		const formatText = config.get<boolean>('formatText', true);
		const addNewLine = config.get<boolean>('addNewLine', true);
		const indentToSelection = config.get<boolean>('indentToSelection', false);

		// –ò—Å–ø–æ–ª—å–∑—É–µ–º retry –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—Å—Ç–∞–≤–∫–∏ —Ç–µ–∫—Å—Ç–∞
		const insertResult = await retryManager.retry(
			() => textInserter.insertText(text, {
				mode: mode as 'cursor' | 'comment' | 'replace' | 'newLine' | 'clipboard',
				formatText,
				addNewLine,
				indentToSelection
			}),
			'text_insertion',
			{ maxAttempts: 2, strategy: 'fixed_delay' as any, baseDelay: 500 }
		);

		if (!insertResult.success) {
			const error = insertResult.lastError || new Error('Text insertion failed after retries');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			throw error;
		}
		
		console.log('‚úÖ Text inserted successfully');
		
	} catch (error) {
		console.error('‚ùå Text insertion failed:', error);
		
		// –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ ErrorHandler –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤—ã—à–µ
		if (!(error as any).handled) {
			const userAction = await errorHandler.handleErrorFromException(error as Error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
		
		throw error; // –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã—à–µ
	}
}

/**
 * –ö–æ–º–∞–Ω–¥—ã —Ä–µ–∂–∏–º–æ–≤ –≤—Å—Ç–∞–≤–∫–∏
 */
async function insertLastTranscription(mode: string): Promise<void> {
	if (!lastTranscribedText) {
		vscode.window.showWarningMessage('No transcribed text available. Please record something first.');
		return;
	}
	
	try {
		// –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∂–∏–º–∞ —á–∞—Ç–∞
		if (mode === 'chat') {
			if (!cursorIntegration || !cursorIntegration.isIntegrationEnabled()) {
				throw new Error('Cursor integration not available');
			}
			
			console.log('üì§ Sending text to Cursor chat...');
			const result = await cursorIntegration.sendToChat(lastTranscribedText);
			
			if (!result.success) {
				throw new Error(result.error || 'Failed to send to chat');
			}
			
			console.log(`‚úÖ Successfully sent to chat via ${result.strategy}`);
			return;
		}
		
		// –û–±—ã—á–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤
		await insertTranscribedTextWithErrorHandling(lastTranscribedText, mode, {
			operation: 'text_insertion',
			isHoldToRecordMode: false,
			timestamp: new Date(),
			additionalData: { 
				textLength: lastTranscribedText.length,
				insertMode: mode,
				parentOperation: 'transcription'
			}
		});
		vscode.window.showInformationMessage(`Text inserted in ${mode} mode`);
	} catch (error) {
		console.error(`‚ùå Failed to insert text in ${mode} mode:`, error);
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
		if (mode === 'chat') {
			vscode.window.showErrorMessage(`Failed to send to chat: ${(error as Error).message}`);
		} else {
			// –û—à–∏–±–∫–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤ insertTranscribedTextWithErrorHandling –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ä–µ–∂–∏–º–æ–≤
		}
		
		throw error; // –ü–µ—Ä–µ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã—à–µ
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è WhisperClient
 */
function initializeWhisperClient(): void {
	console.log('üîß Initializing Whisper client...');
	
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const apiKey = config.get<string>('apiKey');

	if (!apiKey) {
		console.warn('‚ö†Ô∏è OpenAI API key not configured');
		statusBarManager.showWarning('API key not configured');
		return;
	}

	if (!WhisperClient.validateApiKey(apiKey)) {
		console.error('‚ùå Invalid OpenAI API key format');
		statusBarManager.showError('Invalid API key format', 'critical');
		return;
	}

	try {
		whisperClient = new WhisperClient({
			apiKey,
			timeout: config.get<number>('timeout', 30000),
			maxRetries: config.get<number>('maxRetries', 3),
			retryDelay: config.get<number>('retryDelay', 1000),
			baseURL: config.get<string>('baseURL') || undefined
		});
		
		console.log('‚úÖ Whisper client initialized successfully');
		
	} catch (error) {
		const errorMessage = `Failed to initialize Whisper client: ${(error as Error).message}`;
		console.error(errorMessage);
		statusBarManager.showError(errorMessage, 'critical');
	}
}

/**
 * –£—Ç–∏–ª–∏—Ç–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
 */
function openSettings(): void {
	vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper');
}

function showHelp(): void {
	const helpText = `
üé§ **SpeechToTextWhisper Help**

**Recording:**
‚Ä¢ F9 (hold): Hold to record, release to stop
‚Ä¢ Toggle recording: Ctrl+Shift+V (or use command palette)

**Commands:**
‚Ä¢ Voice Scribe: Start Recording
‚Ä¢ Voice Scribe: Stop Recording  
‚Ä¢ Voice Scribe: Toggle Recording
‚Ä¢ Voice Scribe: Insert as Comment
‚Ä¢ Voice Scribe: Replace Selection

**Settings:**
‚Ä¢ OpenAI API Key (required)
‚Ä¢ Language (auto-detect or specific)
‚Ä¢ Insert Mode (cursor/comment/replace)
‚Ä¢ Audio Quality settings

**Troubleshooting:**
‚Ä¢ Check microphone permissions
‚Ä¢ Verify API key is valid
‚Ä¢ Test microphone access
`;

	vscode.window.showInformationMessage(helpText, { modal: true });
}

function showStatus(): void {
	const status = statusBarManager.getStatus();
	const context = textInserter.getActiveContext();
	
	const statusText = `
**SpeechToTextWhisper Status:**

üé§ Recording: ${status.isRecording ? 'Active' : 'Inactive'}
üìä State: ${status.state}
üîß API Client: ${whisperClient ? 'Ready' : 'Not configured'}
üìù Context: ${context.type} (${context.language || 'unknown'})
üíæ Last Error: ${status.lastError || 'None'}
üìã Last Transcription: ${lastTranscribedText ? 'Available' : 'None'}
`;

	vscode.window.showInformationMessage(statusText, { modal: true });
}

function showContextInfo(): void {
	if (!contextManager) {
		vscode.window.showWarningMessage('ContextManager not initialized');
		return;
	}
	
	const context = contextManager.getContext();
	const language = contextManager.getCurrentLanguage();
	
	const contextText = `
**SpeechToTextWhisper Context Information:**

üîç **IDE Type:** ${context.ideType}
üìç **Current Context:** ${context.contextType}

${context.activeEditor ? `üìù **Active Editor:**
‚Ä¢ File: ${context.activeEditor.fileName}
‚Ä¢ Language: ${context.activeEditor.language.name} (${context.activeEditor.language.id})
‚Ä¢ Position: Line ${context.activeEditor.lineNumber}, Column ${context.activeEditor.columnNumber}
‚Ä¢ Comment Style: ${context.activeEditor.language.commentStyle}
${context.activeEditor.language.lineComment ? `‚Ä¢ Line Comment: ${context.activeEditor.language.lineComment}` : ''}
${context.activeEditor.language.blockComment ? `‚Ä¢ Block Comment: ${context.activeEditor.language.blockComment.start} ... ${context.activeEditor.language.blockComment.end}` : ''}
` : ''}

${context.terminal?.isActive ? `üíª **Terminal:** ${context.terminal.name}\n` : ''}

${context.debugger?.isActive ? `üêõ **Debugger:** ${context.debugger.sessionName || 'Active'}\n` : ''}

${context.workspace ? `üìÅ **Workspace:** ${context.workspace.name}
‚Ä¢ Folders: ${context.workspace.folders.length} folder(s)
` : ''}

**Comment Support:**
‚Ä¢ Line Comments: ${language ? contextManager.supportsComments('line') : 'N/A'}
‚Ä¢ Block Comments: ${language ? contextManager.supportsComments('block') : 'N/A'}
‚Ä¢ Preferred Style: ${contextManager.getPreferredCommentStyle() || 'N/A'}
`;

	vscode.window.showInformationMessage(contextText, { modal: true });
}

function refreshContext(): void {
	if (!contextManager) {
		vscode.window.showWarningMessage('ContextManager not initialized');
		return;
	}
	
	try {
		contextManager.refreshContext();
		const context = contextManager.getContext();
		vscode.window.showInformationMessage(
			`üîÑ Context refreshed: ${context.contextType} in ${context.ideType}`
		);
	} catch (error) {
		const errorMessage = (error as Error).message;
		vscode.window.showErrorMessage(`‚ùå Failed to refresh context: ${errorMessage}`);
	}
}

async function checkMicrophone(): Promise<void> {
	try {
		statusBarManager.showProcessing();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å FFmpeg
		const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
		if (!ffmpegCheck.available) {
			throw new Error(`FFmpeg not available: ${ffmpegCheck.error || 'Not found in PATH'}`);
		}
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
		const devices = await FFmpegAudioRecorder.detectInputDevices();
		if (devices.length === 0) {
			throw new Error('No audio input devices found');
		}
		
		statusBarManager.showSuccess('Microphone ready');
		vscode.window.showInformationMessage(`‚úÖ Microphone is working correctly. Found ${devices.length} audio device(s).`);
		
	} catch (error) {
		const errorMessage = (error as Error).message;
		statusBarManager.showError(errorMessage, 'error');
		vscode.window.showErrorMessage(`‚ùå ${errorMessage}`);
	}
}

async function testApiKey(): Promise<void> {
	if (!whisperClient) {
		vscode.window.showWarningMessage('Please configure your OpenAI API key first');
		return;
	}
	
	try {
		statusBarManager.showProcessing();
		
		// –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∞—É–¥–∏–æ blob (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π WAV —Ñ–∞–π–ª)
		const testBlob = new Blob(['test'], { type: 'audio/wav' });
		
		try {
			await whisperClient.transcribe(testBlob);
			statusBarManager.showSuccess('API key validated');
			vscode.window.showInformationMessage('‚úÖ OpenAI API key is working correctly');
		} catch (error) {
			// –û–∂–∏–¥–∞–µ–º–∞—è –æ—à–∏–±–∫–∞ —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏, –Ω–æ API key –≤–∞–ª–∏–¥–µ–Ω –µ—Å–ª–∏ –º—ã –ø–æ–ª—É—á–∏–ª–∏ –æ—Ç–≤–µ—Ç –æ—Ç API
			const errorMessage = (error as Error).message;
			if (errorMessage.includes('audio') || errorMessage.includes('format')) {
				statusBarManager.showSuccess('API key validated');
				vscode.window.showInformationMessage('‚úÖ OpenAI API key is working correctly');
			} else {
				throw error;
			}
		}
		
	} catch (error) {
		const errorMessage = (error as Error).message;
		statusBarManager.showError(errorMessage, 'critical');
		vscode.window.showErrorMessage(`‚ùå API key test failed: ${errorMessage}`);
	}
}

function resetConfiguration(): void {
	vscode.window.showWarningMessage(
		'This will reset all SpeechToTextWhisper settings to defaults. Continue?',
		'Yes', 'No'
	).then(selection => {
		if (selection === 'Yes') {
			const config = vscode.workspace.getConfiguration('speechToTextWhisper');
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∫—Ä–æ–º–µ API –∫–ª—é—á–∞)
			config.update('language', 'auto', vscode.ConfigurationTarget.Global);
			config.update('insertMode', 'cursor', vscode.ConfigurationTarget.Global);
			config.update('formatText', true, vscode.ConfigurationTarget.Global);
			
			vscode.window.showInformationMessage('‚úÖ Configuration reset to defaults');
		}
	});
}

function toggleStatusBar(): void {
	const status = statusBarManager.getStatus();
	if (status.isVisible) {
		statusBarManager.hide();
		vscode.window.showInformationMessage('Status bar hidden');
	} else {
		statusBarManager.show();
		vscode.window.showInformationMessage('Status bar shown');
	}
}

/**
 * –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
 */
function showWelcomeMessage(): void {
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const hasApiKey = config.get<string>('apiKey');
	
	if (!hasApiKey) {
		vscode.window.showInformationMessage(
			'üé§ Welcome to SpeechToTextWhisper! Please configure your OpenAI API key to get started.',
			'Open Settings'
		).then(selection => {
			if (selection === 'Open Settings') {
				openSettings();
			}
		});
	}
}

/**
 * –§—É–Ω–∫—Ü–∏—è –¥–µ–∞–∫—Ç–∏–≤–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 * –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ –æ—Ç–∫–ª—é—á–µ–Ω–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
export function deactivate() {
	console.log('üîå Deactivating SpeechToTextWhisper extension...');
	
	try {
		// –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –µ—Å–ª–∏ –∞–∫—Ç–∏–≤–Ω–∞
		if (audioRecorder && audioRecorder.getIsRecording()) {
			console.log('‚èπÔ∏è Stopping active recording...');
			audioRecorder.stopRecording();
		}
		
		// –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã ContextManager
		if (contextManager) {
			console.log('üîå Disposing ContextManager...');
			contextManager.dispose();
		}
		
		console.log('‚úÖ SpeechToTextWhisper extension deactivated successfully');
		
	} catch (error) {
		console.error('‚ùå Error during deactivation:', error);
	}
}

/**
 * –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ–π—Å—Ç–≤–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
 */
async function handleUserRecoveryAction(userAction: string, context: ErrorContext): Promise<void> {
	console.log(`üîß Handling user recovery action: ${userAction}`);
	
	try {
		// –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤—ã–±–æ—Ä–∞
		if (userAction === 'Open Settings') {
			await recoveryHandler.executeRecoveryAction('open_settings' as any);
		} else if (userAction === 'Check Microphone') {
			await recoveryHandler.executeRecoveryAction('enable_microphone' as any);
		} else if (userAction === 'Retry') {
			await recoveryHandler.executeRecoveryAction('retry' as any);
		} else if (userAction === 'Check Network') {
			await recoveryHandler.executeRecoveryAction('check_network' as any);
		} else if (userAction === 'Reload Extension') {
			await recoveryHandler.executeRecoveryAction('refresh_extension' as any);
		}
	} catch (error) {
		console.error('‚ùå Recovery action failed:', error);
		vscode.window.showErrorMessage(`Recovery action failed: ${(error as Error).message}`);
	}
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ContextManager
 */
function initializeContextManager(): void {
	console.log('üîß Initializing ContextManager...');
	
	const contextEvents: ContextManagerEvents = {
		onContextChange: (context: IDEContext) => {
			console.log(`üîÑ Context changed: ${context.contextType} in ${context.ideType}`);
			
			// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
			adaptToContext(context);
		},
		
		onIDETypeDetected: (ideType: IDEType) => {
			console.log(`üîç IDE detected: ${ideType}`);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è IDE —Å–æ–æ–±—â–µ–Ω–∏—è
			if (ideType === IDEType.CURSOR) {
				console.log('üéØ Cursor IDE detected - AI chat integration available');
			} else if (ideType === IDEType.VSCODE) {
				console.log('üí° VS Code detected - standard functionality enabled');
			}
		},
		
		onLanguageChange: (language) => {
			console.log(`üìù Language changed: ${language.name} (${language.id})`);
			
			// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –ø–æ–¥ —è–∑—ã–∫
			if (textInserter) {
				// TextInserter —É–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç VS Code API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞
				// –Ω–æ —Ç–µ–ø–µ—Ä—å —É –Ω–∞—Å –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∏–ª–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
			}
		}
	};
	
	contextManager = new ContextManager(contextEvents);
	
	console.log('‚úÖ ContextManager initialized successfully');
}

/**
 * –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω–∏—è –∫ —Ç–µ–∫—É—â–µ–º—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
 */
function adaptToContext(context: IDEContext): void {
	try {
		// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ StatusBar –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
		if (statusBarManager) {
			// –í —Ä–µ–∂–∏–º–µ —Ç–µ—Ä–º–∏–Ω–∞–ª–∞ –∏–ª–∏ –æ—Ç–ª–∞–¥—á–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
			if (context.contextType === ContextType.TERMINAL || context.contextType === ContextType.DEBUGGER) {
				// StatusBarManager —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –Ω–æ –º–æ–∂–µ–º –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å tooltip
			}
		}
		
		// –î–ª—è Cursor - –≥–æ—Ç–æ–≤–∏–º—Å—è –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —á–∞—Ç–æ–º
		if (context.ideType === IDEType.CURSOR && context.contextType === ContextType.CHAT) {
			console.log('üí¨ Cursor chat context detected - ready for AI chat integration');
		}
		
		// –ê–¥–∞–ø—Ç–∏—Ä—É–µ–º —Ä–µ–∂–∏–º –≤—Å—Ç–∞–≤–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
		if (context.activeEditor && context.activeEditor.language && contextManager) {
			const language = context.activeEditor.language;
			console.log(`üìù Active file: ${language.name}, supports comments: line=${contextManager.supportsComments('line')}, block=${contextManager.supportsComments('block')}`);
		}
		
	} catch (error) {
		console.error('‚ùå Error adapting to context:', error);
	}
}

/**
 * –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
 */
async function runDiagnostics(): Promise<void> {
	console.log('üîß Running SpeechToTextWhisper diagnostics...');
	
	const diagnosticsResults: string[] = [];
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç–∏–≤–∞—Ü–∏—é —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
	diagnosticsResults.push('‚úÖ Extension activated');
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	const apiKey = config.get<string>('apiKey');
	if (apiKey && apiKey.trim()) {
		diagnosticsResults.push('‚úÖ API key configured');
	} else {
		diagnosticsResults.push('‚ùå API key missing');
	}
	
	try {
		// –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É FFmpeg
		console.log('Running FFmpeg diagnostics...');
		const ffmpegDiagnostics = await FFmpegAudioRecorder.runDiagnostics();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É FFmpeg
		if (ffmpegDiagnostics.ffmpegAvailable.available) {
			diagnosticsResults.push('‚úÖ FFmpeg available');
			if (ffmpegDiagnostics.ffmpegAvailable.version) {
				diagnosticsResults.push(`üì¶ FFmpeg version: ${ffmpegDiagnostics.ffmpegAvailable.version}`);
			}
			if (ffmpegDiagnostics.ffmpegAvailable.path) {
				diagnosticsResults.push(`üìÇ FFmpeg path: ${ffmpegDiagnostics.ffmpegAvailable.path}`);
			}
		} else {
			diagnosticsResults.push(`‚ùå FFmpeg not available: ${ffmpegDiagnostics.ffmpegAvailable.error || 'Not found'}`);
		}
		
		// –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
		diagnosticsResults.push(`üñ•Ô∏è Platform: ${ffmpegDiagnostics.platform}`);
		diagnosticsResults.push(`‚öôÔ∏è Audio input: ${ffmpegDiagnostics.platformCommands.audioInput}`);
		diagnosticsResults.push(`üéôÔ∏è Default device: ${ffmpegDiagnostics.platformCommands.defaultDevice}`);
		
		if (ffmpegDiagnostics.recommendedDevice) {
			diagnosticsResults.push(`üîç Recommended device: ${ffmpegDiagnostics.recommendedDevice}`);
		}
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
		if (ffmpegDiagnostics.inputDevices.length > 0) {
			diagnosticsResults.push(`‚úÖ Audio devices found: ${ffmpegDiagnostics.inputDevices.length}`);
			ffmpegDiagnostics.inputDevices.slice(0, 3).forEach((device, index) => {
				const cleanDevice = device.replace(/\[\w+.*?\]\s*/, '').trim();
				diagnosticsResults.push(`  üì± ${index}: ${cleanDevice}`);
			});
			if (ffmpegDiagnostics.inputDevices.length > 3) {
				diagnosticsResults.push(`  ... and ${ffmpegDiagnostics.inputDevices.length - 3} more devices`);
			}
		} else {
			diagnosticsResults.push('‚ùå No audio input devices found');
		}
		
		// –û—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
		if (ffmpegDiagnostics.errors.length > 0) {
			diagnosticsResults.push('‚ùå Diagnostic errors:');
			ffmpegDiagnostics.errors.forEach(error => {
				diagnosticsResults.push(`  ‚Ä¢ ${error}`);
			});
		}
		
		if (ffmpegDiagnostics.warnings.length > 0) {
			diagnosticsResults.push('‚ö†Ô∏è Diagnostic warnings:');
			ffmpegDiagnostics.warnings.forEach(warning => {
				diagnosticsResults.push(`  ‚Ä¢ ${warning}`);
			});
		}
		
		// –¢–µ—Å—Ç –∑–∞–ø–∏—Å–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ FFmpeg –¥–æ—Å—Ç—É–ø–µ–Ω)
		if (ffmpegDiagnostics.ffmpegAvailable.available) {
			diagnosticsResults.push('');
			diagnosticsResults.push('üß™ Running audio recording test...');
			
			try {
				const testResult = await FFmpegAudioRecorder.testRecording(2);
				
				if (testResult.success) {
					diagnosticsResults.push(`‚úÖ Recording test successful`);
					diagnosticsResults.push(`üìä File size: ${testResult.fileSize} bytes`);
					diagnosticsResults.push(`‚è±Ô∏è Duration: ${testResult.duration}ms`);
				} else {
					diagnosticsResults.push(`‚ùå Recording test failed`);
					if (testResult.error) {
						diagnosticsResults.push(`  Error: ${testResult.error}`);
					}
					if (testResult.command) {
						diagnosticsResults.push(`  Command: ${testResult.command}`);
					}
				}
			} catch (testError) {
				diagnosticsResults.push(`‚ùå Recording test exception: ${(testError as Error).message}`);
			}
		}
		
	} catch (error) {
		diagnosticsResults.push(`‚ùå Diagnostics error: ${(error as Error).message}`);
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
	diagnosticsResults.push('');
	diagnosticsResults.push('üìä Extension states:');
	diagnosticsResults.push(`  Recording state: ${audioRecorder?.getIsRecording() ? 'active' : 'inactive'}`);
	diagnosticsResults.push(`  Current mode: ${currentRecordingMode || 'none'}`);
	diagnosticsResults.push(`  Last transcription: ${lastTranscribedText ? 'available' : 'none'}`);
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
	const recordingMode = config.get<string>('recordingMode', 'chat');
	const language = config.get<string>('language', 'auto');
	const insertMode = config.get<string>('insertMode', 'cursor');
	const inputDevice = config.get<string>('inputDevice', 'auto');
	
	diagnosticsResults.push('');
	diagnosticsResults.push('‚öôÔ∏è Configuration:');
	diagnosticsResults.push(`  Recording mode: ${recordingMode}`);
	diagnosticsResults.push(`  Language: ${language}`);
	diagnosticsResults.push(`  Insert mode: ${insertMode}`);
	diagnosticsResults.push(`  Input device: ${inputDevice}`);
	
	// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
	const message = 'SpeechToTextWhisper Diagnostics:\n\n' + diagnosticsResults.join('\n');
	
	const selection = await vscode.window.showInformationMessage(
		'Diagnostics completed. View results?', 
		'Show Results', 
		'Copy to Clipboard', 
		'Test Recording'
	);
	
	if (selection === 'Show Results') {
		// –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
		const doc = await vscode.workspace.openTextDocument({
			content: message,
			language: 'plaintext'
		});
		await vscode.window.showTextDocument(doc);
	} else if (selection === 'Copy to Clipboard') {
		await vscode.env.clipboard.writeText(message);
		vscode.window.showInformationMessage('Diagnostics copied to clipboard');
	} else if (selection === 'Test Recording') {
		// –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∑–∞–ø–∏—Å–∏
		try {
			await ensureFFmpegAudioRecorder();
			await startRecording();
			vscode.window.showInformationMessage('Test recording started. Stop it manually to test the full flow.');
		} catch (error) {
			vscode.window.showErrorMessage(`Test recording failed: ${(error as Error).message}`);
		}
	}
	
	console.log('Diagnostics completed:', diagnosticsResults);
}

/**
 * –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FFmpeg Audio Recorder
 */
async function ensureFFmpegAudioRecorder(): Promise<void> {
	if (audioRecorder) return;

	console.log('üîß Initializing FFmpeg audio recorder...');

	// –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ FFmpeg
	const ffmpegCheck = await FFmpegAudioRecorder.checkFFmpegAvailability();
	if (!ffmpegCheck.available) {
		const error = new Error('FFmpeg not found. Please install FFmpeg and add it to PATH.');
		
		// –ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ
		const action = await vscode.window.showErrorMessage(
			'FFmpeg is required for audio recording but was not found.',
			'Install Guide', 'Settings'
		);
		
		if (action === 'Install Guide') {
			vscode.env.openExternal(vscode.Uri.parse('https://ffmpeg.org/download.html'));
		} else if (action === 'Settings') {
			vscode.commands.executeCommand('workbench.action.openSettings', 'speechToTextWhisper.ffmpegPath');
		}
		
		throw error;
	}

	// –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	
	// –ü–æ–ª—É—á–∞–µ–º inputDevice –Ω–∞—Å—Ç—Ä–æ–π–∫—É –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
	const inputDeviceSetting = config.get<string>('inputDevice');
	const inputDevice = inputDeviceSetting === 'auto' || !inputDeviceSetting ? undefined : inputDeviceSetting;
	
	// –°–æ–±—ã—Ç–∏—è –¥–ª—è AudioRecorder
	const audioRecorderEvents: AudioRecorderEvents = {
		onRecordingStart: () => {
			console.log('üé§ Recording started');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', true);
			
			statusBarManager.updateRecordingState(true);
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
			vscode.window.showInformationMessage('üé§ Recording started...');
		},
		onRecordingStop: async (audioBlob: Blob) => {
			console.log('‚èπÔ∏è Recording stopped');
			
			// –û–±–Ω–æ–≤–ª—è–µ–º context variables
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			
			statusBarManager.updateRecordingState(false);
			await handleTranscription(audioBlob);
		},
		onError: async (error: Error) => {
			console.error('‚ùå Recording error:', error);
			
			// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
			vscode.commands.executeCommand('setContext', 'speechToTextWhisper.isRecording', false);
			currentRecordingMode = null;
			
			// –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫—É
			const errorMessage = error.message;
			if (!shouldShowError(errorMessage)) {
				return; // –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –æ—à–∏–±–∫–∏
			}
			
			// –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
			const context: ErrorContext = {
				operation: 'audio_recording',
				isHoldToRecordMode: false,
				timestamp: new Date()
			};
			
			// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫–∏ —á–µ—Ä–µ–∑ ErrorHandler
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
		}
	};
	
	audioRecorder = new FFmpegAudioRecorder(audioRecorderEvents, {
		sampleRate: config.get<number>('sampleRate', 16000),
		channelCount: config.get<number>('channels', 1),
		audioFormat: config.get<'wav' | 'mp3' | 'webm' | 'opus'>('audioFormat', 'wav'),
		codec: config.get<string>('audioCodec', 'pcm_s16le'),
		inputDevice: inputDevice,
		ffmpegPath: config.get<string>('ffmpegPath') || undefined,
		maxDuration: config.get<number>('maxRecordingDuration', 60)
	});
	
	console.log('‚úÖ FFmpeg audio recorder initialized');
}

/**
 * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –æ—à–∏–±–∫—É –∏–ª–∏ —ç—Ç–æ —Å–ø–∞–º
 */
function shouldShowError(errorMessage: string): boolean {
	const now = Date.now();
	const timeSinceLastError = now - lastErrorTime;
	
	// –ï—Å–ª–∏ —Ç–∞ –∂–µ –æ—à–∏–±–∫–∞ –≤ —Ç–µ—á–µ–Ω–∏–µ 3 —Å–µ–∫—É–Ω–¥ - –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
	if (lastErrorMessage === errorMessage && timeSinceLastError < MIN_ERROR_INTERVAL) {
		console.log(`‚ö†Ô∏è Suppressing duplicate error: ${errorMessage}`);
		return false;
	}
	
	lastErrorTime = now;
	lastErrorMessage = errorMessage;
	return true;
}

/**
 * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CursorIntegration
 */
function initializeCursorIntegration(): void {
	console.log('üîß Initializing CursorIntegration...');
	
	const config = vscode.workspace.getConfiguration('speechToTextWhisper');
	
	// –ü–æ–ª—É—á–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ enum
	const strategyString = config.get<string>('cursorStrategy', 'aichat_command');
	let primaryStrategy: CursorIntegrationStrategy;
	
	switch (strategyString) {
		case 'aichat_command':
			primaryStrategy = CursorIntegrationStrategy.AICHAT_COMMAND;
			break;
		case 'clipboard':
			primaryStrategy = CursorIntegrationStrategy.CLIPBOARD;
			break;
		case 'command_palette':
			primaryStrategy = CursorIntegrationStrategy.COMMAND_PALETTE;
			break;
		case 'focus_chat':
			primaryStrategy = CursorIntegrationStrategy.FOCUS_CHAT;
			break;
		case 'send_to_chat':
			primaryStrategy = CursorIntegrationStrategy.SEND_TO_CHAT;
			break;
		default:
			console.log(`‚ö†Ô∏è Unknown strategy '${strategyString}', falling back to aichat_command`);
			primaryStrategy = CursorIntegrationStrategy.AICHAT_COMMAND;
	}
	
	console.log(`üéØ Using Cursor integration strategy: ${primaryStrategy}`);
	
	// –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä CursorIntegration
	cursorIntegration = new CursorIntegration({
		primaryStrategy: primaryStrategy,
		fallbackStrategies: [
			CursorIntegrationStrategy.CLIPBOARD,
			CursorIntegrationStrategy.COMMAND_PALETTE,
			CursorIntegrationStrategy.FOCUS_CHAT
		],
		autoFocusChat: true,
		prefixText: config.get<string>('cursorPrefixText', ''),
		suffixText: config.get<string>('cursorSuffixText', ''),
		useMarkdownFormat: config.get<boolean>('cursorUseMarkdown', true),
		timeout: 5000
	}, {
		onChatSent: (text: string, strategy: CursorIntegrationStrategy) => {
			console.log(`‚úÖ Text sent to chat via ${strategy}: "${text.substring(0, 50)}..."`);
		},
		onFallbackUsed: (primary: CursorIntegrationStrategy, fallback: CursorIntegrationStrategy) => {
			console.log(`üîÑ Fallback used: ${primary} -> ${fallback}`);
			vscode.window.showWarningMessage(`Cursor chat: fell back to ${fallback} strategy`);
		},
		onError: (error: Error, strategy: CursorIntegrationStrategy) => {
			console.error(`‚ùå CursorIntegration error with ${strategy}:`, error);
		}
	});
	
	console.log(`‚úÖ CursorIntegration initialized, enabled: ${cursorIntegration.isIntegrationEnabled()}`);
}

/**
 * –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø–∏—Å–∏ —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —á–∞—Ç
 */
async function recordAndSendToChat(): Promise<void> {
	const context: ErrorContext = {
		operation: 'record_and_send_to_chat',
		isHoldToRecordMode: false,
		timestamp: new Date()
	};

	try {
		console.log('üé§ Starting record and send to chat...');
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å Cursor
		if (!cursorIntegration || !cursorIntegration.isIntegrationEnabled()) {
			throw new Error('Cursor integration not available. Please use Cursor IDE.');
		}
		
		// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–ø–∏—Å–∏
		currentRecordingMode = 'chat';
		
		// –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
		await startRecording();
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
		vscode.window.showInformationMessage('üé§ Recording... Release F9 to send to chat');
		
	} catch (error) {
		console.error('‚ùå Record and send to chat failed:', error);
		currentRecordingMode = null; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

/**
 * –ö–æ–º–∞–Ω–¥–∞ –∑–∞–ø–∏—Å–∏ –≤ –±—É—Ñ–µ—Ä –æ–±–º–µ–Ω–∞
 */
async function recordToClipboard(): Promise<void> {
	const context: ErrorContext = {
		operation: 'record_to_clipboard',
		isHoldToRecordMode: false,
		timestamp: new Date()
	};

	try {
		console.log('üìã Starting record to clipboard...');
		
		// –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–ø–∏—Å–∏
		currentRecordingMode = 'clipboard';
		
		// –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
		await startRecording();
		
		// –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ
		vscode.window.showInformationMessage('üé§ Recording... Release Ctrl+Shift+V to copy to clipboard');
		
	} catch (error) {
		console.error('‚ùå Record to clipboard failed:', error);
		currentRecordingMode = null; // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

/**
 * –ö–æ–º–∞–Ω–¥—ã –∑–∞–ø–∏—Å–∏
 */
async function startRecording(): Promise<void> {
	const context: ErrorContext = {
		operation: 'start_recording',
		isHoldToRecordMode: false,
		timestamp: new Date()
	};

	try {
		console.log('‚ñ∂Ô∏è Starting recording...');
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
		const now = Date.now();
		if (now - lastRecordingStartTime < MIN_RECORDING_INTERVAL) {
			console.log('‚ö†Ô∏è Too frequent recording attempts, skipping');
			return;
		}
		lastRecordingStartTime = now;
		
		// –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é FFmpeg Audio Recorder
		await ensureFFmpegAudioRecorder();
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–¥–µ—Ç –ª–∏ —É–∂–µ –∑–∞–ø–∏—Å—å
		if (audioRecorder && audioRecorder.getIsRecording()) {
			console.log('‚ö†Ô∏è Recording already in progress, skipping start');
			return;
		}
		
		// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ —Å retry
		const microphoneResult = await retryManager.retryMicrophoneOperation(
			async () => {
				const hasPermission = await FFmpegAudioRecorder.checkMicrophonePermission();
				if (hasPermission.state !== 'granted') {
					throw new Error('Microphone permission not granted');
				}
				return hasPermission;
			},
			'microphone_permission_check'
		);

		if (!microphoneResult.success) {
			const error = microphoneResult.lastError || new Error('Microphone access failed');
			const userAction = await errorHandler.handleErrorFromException(error, context);
			
			if (userAction && userAction !== 'ignore') {
				await handleUserRecoveryAction(userAction, context);
			}
			return;
		}
		
		if (!audioRecorder) {
			throw new Error('Failed to initialize audio recorder');
		}
		
		await audioRecorder.startRecording();
		
	} catch (error) {
		console.error('‚ùå Failed to start recording:', error);
		
		const userAction = await errorHandler.handleErrorFromException(error as Error, context);
		
		if (userAction && userAction !== 'ignore') {
			await handleUserRecoveryAction(userAction, context);
		}
	}
}

function stopRecording(): void {
	const context: ErrorContext = {
		operation: 'stop_recording',
		isHoldToRecordMode: false,
		timestamp: new Date()
	};

	try {
		console.log('‚èπÔ∏è Stopping recording...');
		
		if (!audioRecorder) {
			console.warn('Audio recorder not initialized');
			return;
		}
		
		audioRecorder.stopRecording();
		
		// –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ä–µ–∂–∏–º –∑–∞–ø–∏—Å–∏
		currentRecordingMode = null;
		
	} catch (error) {
		console.error('‚ùå Failed to stop recording:', error);
		
		// –î–ª—è stop recording –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫
		errorHandler.handleErrorFromException(error as Error, context);
	}
}
