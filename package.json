{
  "name": "speech-to-text-whisper",
  "displayName": "Speech to Text with Whisper",
  "description": "Transform speech to text using OpenAI Whisper API with seamless VS Code and Cursor IDE integration",
  "version": "0.1.0",
  "publisher": "speak-y",
  "icon": "media/icon.png",
  "galleryBanner": {
    "color": "#1e1e1e",
    "theme": "dark"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/alexstich/vs-code-speech-to-text"
  },
  "bugs": {
    "url": "https://github.com/alexstich/vs-code-speech-to-text/issues"
  },
  "homepage": "https://github.com/alexstich/vs-code-speech-to-text#readme",
  "license": "MIT",
  "engines": {
    "vscode": "^1.74.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Productivity"
  ],
  "keywords": [
    "speech",
    "voice",
    "transcription",
    "whisper",
    "openai",
    "audio",
    "ai",
    "cursor",
    "dictation",
    "accessibility",
    "ffmpeg",
    "cross-platform",
    "recording"
  ],
  "activationEvents": [
    "onCommand:speechToTextWhisper.startRecording",
    "onCommand:speechToTextWhisper.toggleRecording",
    "onCommand:speechToTextWhisper.sendToChat"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "viewsContainers": {
      "activitybar": [
        {
          "id": "speechToTextWhisper",
          "title": "Speech to Text",
          "icon": "$(unmute)"
        }
      ]
    },
    "views": {
      "speechToTextWhisper": [
        {
          "id": "speechToTextWhisper.deviceManager",
          "name": "Audio Devices",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.audioSettings",
          "name": "FFmpeg Settings",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.diagnostics",
          "name": "Diagnostics",
          "when": "true"
        }
      ]
    },
    "commands": [
      {
        "command": "speechToTextWhisper.recordAndSendToChat",
        "title": "Record and Send to Chat",
        "category": "Speech to Text with Whisper",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "speechToTextWhisper.recordToClipboard",
        "title": "Record to Clipboard",
        "category": "Speech to Text with Whisper",
        "icon": "$(clippy)"
      },
      {
        "command": "speechToTextWhisper.openSettings",
        "title": "Open Settings",
        "category": "Speech to Text with Whisper",
        "icon": "$(settings-gear)"
      },
      {
        "command": "speechToTextWhisper.runDiagnostics",
        "title": "Run Diagnostics",
        "category": "Speech to Text with Whisper",
        "icon": "$(debug)"
      }
    ],
    "keybindings": [
      {
        "command": "speechToTextWhisper.recordAndSendToChat",
        "key": "F9",
        "when": "true"
      },
      {
        "command": "speechToTextWhisper.recordToClipboard",
        "key": "ctrl+shift+v",
        "mac": "cmd+shift+v",
        "when": "true"
      }
    ],
    "menus": {
      "view/title": [
        {
          "command": "speechToTextWhisper.audioSettings.refresh",
          "when": "view == speechToTextWhisper.audioSettings",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.audioSettings.detectDevices",
          "when": "view == speechToTextWhisper.audioSettings",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.deviceManager.refresh",
          "when": "view == speechToTextWhisper.deviceManager",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.diagnostics.runAll",
          "when": "view == speechToTextWhisper.diagnostics",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.openSettings",
          "when": "view == speechToTextWhisper.audioSettings || view == speechToTextWhisper.deviceManager || view == speechToTextWhisper.diagnostics",
          "group": "1_settings"
        }
      ],
      "view/item/context": [
        {
          "command": "speechToTextWhisper.audioSettings.selectDevice",
          "when": "view == speechToTextWhisper.deviceManager && viewItem == audioDevice"
        },
        {
          "command": "speechToTextWhisper.audioSettings.testDevice",
          "when": "view == speechToTextWhisper.deviceManager && viewItem == audioDevice"
        }
      ],
      "editor/context": [
        {
          "command": "speechToTextWhisper.toggleRecording",
          "group": "speechToTextWhisper",
          "when": "editorTextFocus"
        },
        {
          "command": "speechToTextWhisper.insertAsComment",
          "group": "speechToTextWhisper",
          "when": "editorTextFocus"
        }
      ],
      "commandPalette": [
        {
          "command": "speechToTextWhisper.recordAndSendToChat",
          "when": "true"
        },
        {
          "command": "speechToTextWhisper.recordToClipboard",
          "when": "true"
        },
        {
          "command": "speechToTextWhisper.openSettings",
          "when": "true"
        },
        {
          "command": "speechToTextWhisper.runDiagnostics",
          "when": "true"
        }
      ]
    },
    "configuration": {
      "title": "Speech to Text with Whisper",
      "properties": {
        "speechToTextWhisper.apiKey": {
          "type": "string",
          "description": "OpenAI API Key for Whisper transcription",
          "scope": "application",
          "order": 1
        },
        "speechToTextWhisper.language": {
          "type": "string",
          "default": "auto",
          "description": "Language for transcription (auto-detect if 'auto')",
          "enum": [
            "auto",
            "en",
            "ru",
            "es",
            "fr",
            "de",
            "it",
            "pt",
            "zh",
            "ja",
            "ko",
            "ar",
            "bg",
            "ca",
            "cs",
            "da",
            "el",
            "et",
            "fi",
            "he",
            "hi",
            "hr",
            "hu",
            "is",
            "id",
            "lv",
            "lt",
            "mk",
            "ms",
            "mt",
            "nl",
            "no",
            "pl",
            "ro",
            "sk",
            "sl",
            "sr",
            "sv",
            "th",
            "tr",
            "uk",
            "vi"
          ],
          "enumDescriptions": [
            "Auto-detect language",
            "English",
            "Russian",
            "Spanish",
            "French",
            "German",
            "Italian",
            "Portuguese",
            "Chinese",
            "Japanese",
            "Korean",
            "Arabic",
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "Greek",
            "Estonian",
            "Finnish",
            "Hebrew",
            "Hindi",
            "Croatian",
            "Hungarian",
            "Icelandic",
            "Indonesian",
            "Latvian",
            "Lithuanian",
            "Macedonian",
            "Malay",
            "Maltese",
            "Dutch",
            "Norwegian",
            "Polish",
            "Romanian",
            "Slovak",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Vietnamese"
          ],
          "order": 2
        },
        "speechToTextWhisper.whisperModel": {
          "type": "string",
          "enum": [
            "whisper-1"
          ],
          "default": "whisper-1",
          "description": "OpenAI Whisper model to use for transcription",
          "order": 2.1
        },
        "speechToTextWhisper.languageDetectionConfidence": {
          "type": "number",
          "default": 0.8,
          "minimum": 0.1,
          "maximum": 1,
          "description": "Minimum confidence threshold for auto language detection",
          "order": 2.2
        },
        "speechToTextWhisper.recordingMode": {
          "type": "string",
          "enum": [
            "chat",
            "clipboard"
          ],
          "default": "chat",
          "description": "Recording mode: send to chat or copy to clipboard",
          "order": 3
        },
        "speechToTextWhisper.audioQuality": {
          "type": "string",
          "enum": [
            "standard",
            "high",
            "ultra"
          ],
          "default": "standard",
          "description": "Audio recording quality",
          "enumDescriptions": [
            "Standard quality (16kHz, adequate for most speech)",
            "High quality (44.1kHz, better accuracy)",
            "Ultra quality (48kHz, maximum accuracy)"
          ],
          "order": 5
        },
        "speechToTextWhisper.audioFormat": {
          "type": "string",
          "enum": [
            "wav",
            "mp3",
            "webm"
          ],
          "default": "wav",
          "description": "Audio format for transcription",
          "enumDescriptions": [
            "WAV format (uncompressed, best quality)",
            "MP3 format (compressed, smaller size)",
            "WebM format (modern, good compression)"
          ],
          "order": 5.1
        },
        "speechToTextWhisper.ffmpegPath": {
          "type": "string",
          "default": "",
          "description": "Path to FFmpeg executable (leave empty for auto-detection)",
          "scope": "application",
          "order": 5.15
        },
        "speechToTextWhisper.inputDevice": {
          "type": "string",
          "default": "auto",
          "description": "Audio input device (auto-detect or specific device)",
          "order": 5.16
        },
        "speechToTextWhisper.audioCodec": {
          "type": "string",
          "enum": [
            "pcm_s16le",
            "aac",
            "mp3",
            "opus"
          ],
          "default": "pcm_s16le",
          "description": "Audio codec for recording",
          "enumDescriptions": [
            "PCM 16-bit (WAV, uncompressed)",
            "AAC (compressed, good quality)",
            "MP3 (compressed, wide compatibility)",
            "Opus (modern, excellent compression)"
          ],
          "order": 5.17
        },
        "speechToTextWhisper.sampleRate": {
          "type": "number",
          "enum": [
            16000,
            22050,
            44100,
            48000
          ],
          "default": 16000,
          "description": "Audio sample rate in Hz",
          "enumDescriptions": [
            "16kHz (standard for speech)",
            "22kHz (better quality)",
            "44.1kHz (CD quality)",
            "48kHz (professional quality)"
          ],
          "order": 5.18
        },
        "speechToTextWhisper.channels": {
          "type": "number",
          "enum": [
            1,
            2
          ],
          "default": 1,
          "description": "Number of audio channels",
          "enumDescriptions": [
            "Mono (recommended for speech)",
            "Stereo"
          ],
          "order": 5.19
        },
        "speechToTextWhisper.noiseReduction": {
          "type": "boolean",
          "default": true,
          "description": "Apply noise reduction to audio before transcription",
          "order": 5.2
        },
        "speechToTextWhisper.autoGain": {
          "type": "boolean",
          "default": true,
          "description": "Automatically adjust microphone gain for optimal levels",
          "order": 5.3
        },
        "speechToTextWhisper.echoCancellation": {
          "type": "boolean",
          "default": true,
          "description": "Enable echo cancellation for better audio quality",
          "order": 5.4
        },
        "speechToTextWhisper.noiseSuppression": {
          "type": "boolean",
          "default": true,
          "description": "Enable noise suppression for cleaner audio",
          "order": 5.5
        },
        "speechToTextWhisper.enableCursorIntegration": {
          "type": "boolean",
          "default": true,
          "description": "Enable integration with Cursor AI chat",
          "order": 6
        },
        "speechToTextWhisper.cursorStrategy": {
          "type": "string",
          "enum": [
            "aichat_command",
            "clipboard",
            "command_palette",
            "focus_chat",
            "send_to_chat"
          ],
          "default": "aichat_command",
          "description": "Strategy for Cursor chat integration",
          "enumDescriptions": [
            "Open new AI chat and paste text directly (RECOMMENDED)",
            "Copy to clipboard and paste in chat",
            "Use command palette to send",
            "Focus chat panel and insert",
            "Direct send to chat API"
          ],
          "order": 7
        },
        "speechToTextWhisper.autoSendToChat": {
          "type": "boolean",
          "default": false,
          "description": "Automatically send transcription to Cursor chat when chat context is detected",
          "order": 8
        },
        "speechToTextWhisper.cursorPrefixText": {
          "type": "string",
          "default": "",
          "description": "Text to add before transcription when sending to Cursor chat",
          "order": 9
        },
        "speechToTextWhisper.cursorSuffixText": {
          "type": "string",
          "default": "",
          "description": "Text to add after transcription when sending to Cursor chat",
          "order": 10
        },
        "speechToTextWhisper.cursorUseMarkdown": {
          "type": "boolean",
          "default": true,
          "description": "Format text with markdown when sending to Cursor chat",
          "order": 21.5
        },
        "speechToTextWhisper.showStatusBar": {
          "type": "boolean",
          "default": true,
          "description": "Show recording status in status bar",
          "order": 12
        },
        "speechToTextWhisper.autoDetectContext": {
          "type": "boolean",
          "default": true,
          "description": "Automatically detect IDE context (editor, chat, terminal)",
          "order": 13
        },
        "speechToTextWhisper.maxRecordingDuration": {
          "type": "number",
          "default": 60,
          "minimum": 5,
          "maximum": 300,
          "description": "Maximum recording duration in seconds",
          "order": 14
        },
        "speechToTextWhisper.prompt": {
          "type": "string",
          "default": "",
          "description": "Optional context prompt to improve transcription accuracy",
          "order": 15
        },
        "speechToTextWhisper.responseFormat": {
          "type": "string",
          "enum": [
            "text",
            "json",
            "verbose_json"
          ],
          "default": "text",
          "description": "Response format from Whisper API",
          "enumDescriptions": [
            "Plain text response",
            "JSON with basic metadata",
            "Detailed JSON with timestamps and confidence"
          ],
          "order": 15.1
        },
        "speechToTextWhisper.enableTimestamps": {
          "type": "boolean",
          "default": false,
          "description": "Include timestamps in transcription (requires JSON format)",
          "order": 15.2
        },
        "speechToTextWhisper.silenceDetection": {
          "type": "boolean",
          "default": true,
          "description": "Automatically detect silence and stop recording",
          "order": 15.3
        },
        "speechToTextWhisper.silenceThreshold": {
          "type": "number",
          "default": 2,
          "minimum": 0.5,
          "maximum": 10,
          "description": "Silence duration in seconds before auto-stop",
          "order": 15.4
        },
        "speechToTextWhisper.temperature": {
          "type": "number",
          "default": 0.1,
          "minimum": 0,
          "maximum": 1,
          "description": "OpenAI temperature (0 = deterministic, 1 = creative)",
          "order": 16
        },
        "speechToTextWhisper.timeout": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 120000,
          "description": "API request timeout in milliseconds",
          "order": 17
        },
        "speechToTextWhisper.maxRetries": {
          "type": "number",
          "default": 3,
          "minimum": 0,
          "maximum": 10,
          "description": "Maximum number of retry attempts for failed API requests",
          "order": 18
        },
        "speechToTextWhisper.retryDelay": {
          "type": "number",
          "default": 1000,
          "minimum": 100,
          "maximum": 10000,
          "description": "Delay between retry attempts in milliseconds",
          "order": 19
        },
        "speechToTextWhisper.formatText": {
          "type": "boolean",
          "default": true,
          "description": "Format transcribed text (capitalize, trim whitespace)",
          "order": 20
        },
        "speechToTextWhisper.addNewLine": {
          "type": "boolean",
          "default": true,
          "description": "Add new line after inserted text",
          "order": 21
        },
        "speechToTextWhisper.indentToSelection": {
          "type": "boolean",
          "default": false,
          "description": "Indent inserted text to match selection",
          "order": 22
        },
        "speechToTextWhisper.statusBarPosition": {
          "type": "string",
          "enum": [
            "left",
            "right"
          ],
          "default": "right",
          "description": "Position of status bar indicator",
          "order": 23
        },
        "speechToTextWhisper.showTooltips": {
          "type": "boolean",
          "default": true,
          "description": "Show helpful tooltips in status bar",
          "order": 24
        },
        "speechToTextWhisper.enableAnimations": {
          "type": "boolean",
          "default": true,
          "description": "Enable status bar animations",
          "order": 25
        },
        "speechToTextWhisper.autoHideSuccess": {
          "type": "boolean",
          "default": true,
          "description": "Automatically hide success messages",
          "order": 26
        },
        "speechToTextWhisper.successDuration": {
          "type": "number",
          "default": 2000,
          "minimum": 500,
          "maximum": 10000,
          "description": "Duration to show success messages (ms)",
          "order": 27
        },
        "speechToTextWhisper.errorDuration": {
          "type": "number",
          "default": 3000,
          "minimum": 1000,
          "maximum": 10000,
          "description": "Duration to show error messages (ms)",
          "order": 28
        },
        "speechToTextWhisper.baseURL": {
          "type": "string",
          "default": "",
          "description": "Custom OpenAI API base URL (leave empty for default)",
          "order": 29
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run compile",
    "compile": "tsc -p ./",
    "watch": "tsc -watch -p ./",
    "pretest": "npm run compile && npm run lint",
    "lint": "eslint src",
    "test": "vscode-test",
    "test:unit": "mocha out/test/unit/**/*.test.js --timeout 5000",
    "test:integration": "vscode-test",
    "test:cursor": "npm run compile && vscode-test --grep \"Cursor Integration - Real IDE Tests\"",
    "package": "vsce package"
  },
  "devDependencies": {
    "@istanbuljs/nyc-config-typescript": "^1.0.2",
    "@types/mocha": "^10.0.10",
    "@types/nock": "^10.0.3",
    "@types/node": "20.x",
    "@types/sinon": "^17.0.4",
    "@types/tmp": "^0.2.6",
    "@types/vscode": "^1.74.0",
    "@types/which": "^3.0.4",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.5.2",
    "esbuild": "^0.25.3",
    "eslint": "^9.25.1",
    "mocha": "^11.5.0",
    "nock": "^14.0.4",
    "npm-run-all": "^4.1.5",
    "nyc": "^17.1.0",
    "sinon": "^20.0.0",
    "source-map-support": "^0.5.21",
    "typescript": "^5.8.3"
  },
  "nyc": {
    "extends": "@istanbuljs/nyc-config-typescript",
    "include": [
      "out/core/**/*.js",
      "out/ui/**/*.js",
      "out/utils/**/*.js",
      "out/integrations/**/*.js"
    ],
    "exclude": [
      "out/test/**/*.js",
      "out/**/*.test.js",
      "out/mocks/**/*.js"
    ],
    "reporter": [
      "text",
      "html",
      "lcov"
    ],
    "all": true,
    "check-coverage": true,
    "lines": 80,
    "statements": 80,
    "functions": 80,
    "branches": 70
  },
  "dependencies": {
    "task-master-ai": "^0.15.0",
    "tmp": "^0.2.3",
    "which": "^5.0.0"
  }
}
