{
  "name": "voice-scribe",
  "displayName": "VoiceScribe - Speech to Text",
  "description": "Transform speech to text using OpenAI Whisper API with seamless VS Code and Cursor IDE integration",
  "version": "0.1.0",
  "publisher": "voicescribe",
  "icon": "media/icon.png",
  "galleryBanner": {
    "color": "#1e1e1e",
    "theme": "dark"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/yourusername/voice-scribe-extension"
  },
  "bugs": {
    "url": "https://github.com/yourusername/voice-scribe-extension/issues"
  },
  "homepage": "https://github.com/yourusername/voice-scribe-extension#readme",
  "license": "MIT",
  "engines": {
    "vscode": "^1.74.0"
  },
  "categories": [
    "Other",
    "Machine Learning",
    "Productivity"
  ],
  "keywords": [
    "speech",
    "voice",
    "transcription",
    "whisper",
    "openai",
    "audio",
    "ai",
    "cursor",
    "dictation",
    "accessibility"
  ],
  "activationEvents": [
    "onCommand:voiceScribe.startRecording",
    "onCommand:voiceScribe.toggleRecording",
    "onCommand:voiceScribe.sendToChat"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "voiceScribe.startRecording",
        "title": "Start Voice Recording",
        "category": "VoiceScribe",
        "icon": "$(record)"
      },
      {
        "command": "voiceScribe.stopRecording",
        "title": "Stop Voice Recording",
        "category": "VoiceScribe",
        "icon": "$(record)"
      },
      {
        "command": "voiceScribe.toggleRecording",
        "title": "Toggle Voice Recording",
        "category": "VoiceScribe",
        "icon": "$(mic)"
      },
      {
        "command": "voiceScribe.startHoldToRecord",
        "title": "Start Hold-to-Record",
        "category": "VoiceScribe",
        "icon": "$(mic)"
      },
      {
        "command": "voiceScribe.stopHoldToRecord",
        "title": "Stop Hold-to-Record",
        "category": "VoiceScribe",
        "icon": "$(mic-filled)"
      },
      {
        "command": "voiceScribe.insertAtCursor",
        "title": "Insert Last Transcription at Cursor",
        "category": "VoiceScribe",
        "icon": "$(edit)"
      },
      {
        "command": "voiceScribe.insertAsComment",
        "title": "Insert Last Transcription as Comment",
        "category": "VoiceScribe",
        "icon": "$(comment)"
      },
      {
        "command": "voiceScribe.replaceSelection",
        "title": "Replace Selection with Last Transcription",
        "category": "VoiceScribe",
        "icon": "$(replace)"
      },
      {
        "command": "voiceScribe.copyToClipboard",
        "title": "Copy Last Transcription to Clipboard",
        "category": "VoiceScribe",
        "icon": "$(clippy)"
      },
      {
        "command": "voiceScribe.sendToChat",
        "title": "Record and Send to AI Chat",
        "category": "VoiceScribe",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "voiceScribe.openSettings",
        "title": "Open VoiceScribe Settings",
        "category": "VoiceScribe",
        "icon": "$(settings-gear)"
      },
      {
        "command": "voiceScribe.showHelp",
        "title": "Show VoiceScribe Help",
        "category": "VoiceScribe",
        "icon": "$(question)"
      },
      {
        "command": "voiceScribe.showStatus",
        "title": "Show VoiceScribe Status",
        "category": "VoiceScribe",
        "icon": "$(info)"
      },
      {
        "command": "voiceScribe.checkMicrophone",
        "title": "Check Microphone",
        "category": "VoiceScribe",
        "icon": "$(device-microphone)"
      },
      {
        "command": "voiceScribe.testApiKey",
        "title": "Test OpenAI API Key",
        "category": "VoiceScribe",
        "icon": "$(key)"
      },
      {
        "command": "voiceScribe.showContext",
        "title": "Show Context Information",
        "category": "VoiceScribe",
        "icon": "$(info)"
      },
      {
        "command": "voiceScribe.refreshContext",
        "title": "Refresh Context",
        "category": "VoiceScribe",
        "icon": "$(refresh)"
      },
      {
        "command": "voiceScribe.sendToChat",
        "title": "Send Last Transcription to Cursor Chat",
        "category": "VoiceScribe",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "voiceScribe.recordAndSendToChat",
        "title": "Record and Send to Cursor Chat",
        "category": "VoiceScribe",
        "icon": "$(microphone)"
      },
      {
        "command": "voiceScribe.resetConfiguration",
        "title": "Reset Configuration",
        "category": "VoiceScribe",
        "icon": "$(refresh)"
      },
      {
        "command": "voiceScribe.toggleStatusBar",
        "title": "Toggle Status Bar",
        "category": "VoiceScribe",
        "icon": "$(eye)"
      },
      {
        "command": "voiceScribe.showQualitySettings",
        "title": "Show Audio Quality Settings",
        "category": "VoiceScribe",
        "icon": "$(settings)"
      },
      {
        "command": "voiceScribe.applyQualityPreset",
        "title": "Apply Audio Quality Preset",
        "category": "VoiceScribe",
        "icon": "$(star)"
      },
      {
        "command": "voiceScribe.optimizeForContext",
        "title": "Optimize Audio for Context",
        "category": "VoiceScribe",
        "icon": "$(target)"
      },
      {
        "command": "voiceScribe.exportQualitySettings",
        "title": "Export Audio Quality Settings",
        "category": "VoiceScribe",
        "icon": "$(export)"
      },
      {
        "command": "voiceScribe.importQualitySettings",
        "title": "Import Audio Quality Settings",
        "category": "VoiceScribe",
        "icon": "$(import)"
      }
    ],
    "keybindings": [
      {
        "command": "voiceScribe.startHoldToRecord",
        "key": "F9",
        "when": "!voiceScribe.holdToRecordActive && voiceScribe.recordingMode == 'hold'"
      },
      {
        "command": "voiceScribe.stopHoldToRecord",
        "key": "F9",
        "when": "voiceScribe.holdToRecordActive && voiceScribe.recordingMode == 'hold'"
      },
      {
        "command": "voiceScribe.toggleRecording",
        "key": "F9",
        "when": "voiceScribe.recordingMode == 'toggle'"
      },
      {
        "command": "voiceScribe.toggleRecording",
        "key": "ctrl+shift+v",
        "mac": "cmd+shift+v",
        "when": "editorTextFocus"
      },
      {
        "command": "voiceScribe.sendToChat",
        "key": "ctrl+shift+alt+v",
        "mac": "cmd+shift+alt+v",
        "when": "true"
      },
      {
        "command": "voiceScribe.insertAsComment",
        "key": "ctrl+shift+c",
        "mac": "cmd+shift+c",
        "when": "editorTextFocus"
      },
      {
        "command": "voiceScribe.showHelp",
        "key": "F1",
        "when": "voiceScribe.active"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "command": "voiceScribe.toggleRecording",
          "group": "voiceScribe",
          "when": "editorTextFocus"
        },
        {
          "command": "voiceScribe.insertAsComment",
          "group": "voiceScribe",
          "when": "editorTextFocus"
        }
      ],
      "commandPalette": [
        {
          "command": "voiceScribe.startRecording",
          "when": "true"
        },
        {
          "command": "voiceScribe.stopRecording",
          "when": "voiceScribe.isRecording"
        },
        {
          "command": "voiceScribe.toggleRecording",
          "when": "true"
        },
        {
          "command": "voiceScribe.sendToChat",
          "when": "true"
        },
        {
          "command": "voiceScribe.insertAsComment",
          "when": "editorTextFocus"
        },
        {
          "command": "voiceScribe.openSettings",
          "when": "true"
        }
      ]
    },
    "configuration": {
      "title": "VoiceScribe",
      "properties": {
        "voiceScribe.apiKey": {
          "type": "string",
          "description": "OpenAI API Key for Whisper transcription",
          "scope": "application",
          "order": 1
        },
        "voiceScribe.language": {
          "type": "string",
          "default": "auto",
          "description": "Language for transcription (auto-detect if 'auto')",
          "enum": [
            "auto",
            "en",
            "ru",
            "es",
            "fr",
            "de",
            "it",
            "pt",
            "zh",
            "ja",
            "ko",
            "ar",
            "bg",
            "ca",
            "cs",
            "da",
            "el",
            "et",
            "fi",
            "he",
            "hi",
            "hr",
            "hu",
            "is",
            "id",
            "lv",
            "lt",
            "mk",
            "ms",
            "mt",
            "nl",
            "no",
            "pl",
            "ro",
            "sk",
            "sl",
            "sr",
            "sv",
            "th",
            "tr",
            "uk",
            "vi"
          ],
          "enumDescriptions": [
            "Auto-detect language",
            "English",
            "Russian",
            "Spanish",
            "French",
            "German",
            "Italian",
            "Portuguese",
            "Chinese",
            "Japanese",
            "Korean",
            "Arabic",
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "Greek",
            "Estonian",
            "Finnish",
            "Hebrew",
            "Hindi",
            "Croatian",
            "Hungarian",
            "Icelandic",
            "Indonesian",
            "Latvian",
            "Lithuanian",
            "Macedonian",
            "Malay",
            "Maltese",
            "Dutch",
            "Norwegian",
            "Polish",
            "Romanian",
            "Slovak",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Vietnamese"
          ],
          "order": 2
        },
        "voiceScribe.whisperModel": {
          "type": "string",
          "enum": [
            "whisper-1"
          ],
          "default": "whisper-1",
          "description": "OpenAI Whisper model to use for transcription",
          "order": 2.1
        },
        "voiceScribe.languageDetectionConfidence": {
          "type": "number",
          "default": 0.8,
          "minimum": 0.1,
          "maximum": 1,
          "description": "Minimum confidence threshold for auto language detection",
          "order": 2.2
        },
        "voiceScribe.recordingMode": {
          "type": "string",
          "enum": [
            "hold",
            "toggle"
          ],
          "default": "hold",
          "description": "Recording mode: hold button or toggle on/off",
          "order": 3
        },
        "voiceScribe.insertMode": {
          "type": "string",
          "enum": [
            "cursor",
            "comment",
            "replace"
          ],
          "default": "cursor",
          "description": "How to insert transcribed text",
          "enumDescriptions": [
            "Insert at cursor position",
            "Insert as comment",
            "Replace selected text"
          ],
          "order": 4
        },
        "voiceScribe.audioQuality": {
          "type": "string",
          "enum": [
            "standard",
            "high",
            "ultra"
          ],
          "default": "standard",
          "description": "Audio recording quality",
          "enumDescriptions": [
            "Standard quality (16kHz, adequate for most speech)",
            "High quality (44.1kHz, better accuracy)",
            "Ultra quality (48kHz, maximum accuracy)"
          ],
          "order": 5
        },
        "voiceScribe.audioFormat": {
          "type": "string",
          "enum": [
            "wav",
            "mp3",
            "webm"
          ],
          "default": "wav",
          "description": "Audio format for transcription",
          "enumDescriptions": [
            "WAV format (uncompressed, best quality)",
            "MP3 format (compressed, smaller size)",
            "WebM format (modern, good compression)"
          ],
          "order": 5.1
        },
        "voiceScribe.noiseReduction": {
          "type": "boolean",
          "default": true,
          "description": "Apply noise reduction to audio before transcription",
          "order": 5.2
        },
        "voiceScribe.autoGain": {
          "type": "boolean",
          "default": true,
          "description": "Automatically adjust microphone gain for optimal levels",
          "order": 5.3
        },
        "voiceScribe.enableCursorIntegration": {
          "type": "boolean",
          "default": true,
          "description": "Enable integration with Cursor AI chat",
          "order": 6
        },
        "voiceScribe.cursorStrategy": {
          "type": "string",
          "enum": [
            "clipboard",
            "command_palette",
            "focus_chat",
            "send_to_chat"
          ],
          "default": "clipboard",
          "description": "Strategy for Cursor chat integration",
          "enumDescriptions": [
            "Copy to clipboard and paste in chat",
            "Use command palette to send",
            "Focus chat panel and insert",
            "Direct send to chat API"
          ],
          "order": 7
        },
        "voiceScribe.autoSendToChat": {
          "type": "boolean",
          "default": false,
          "description": "Automatically send transcription to Cursor chat when chat context is detected",
          "order": 8
        },
        "voiceScribe.cursorPrefixText": {
          "type": "string",
          "default": "",
          "description": "Text to add before transcription when sending to Cursor chat",
          "order": 9
        },
        "voiceScribe.cursorSuffixText": {
          "type": "string",
          "default": "",
          "description": "Text to add after transcription when sending to Cursor chat",
          "order": 10
        },
        "voiceScribe.cursorUseMarkdown": {
          "type": "boolean",
          "default": true,
          "description": "Format text with markdown when sending to Cursor chat",
          "order": 21.5
        },
        "voiceScribe.showStatusBar": {
          "type": "boolean",
          "default": true,
          "description": "Show recording status in status bar",
          "order": 12
        },
        "voiceScribe.autoDetectContext": {
          "type": "boolean",
          "default": true,
          "description": "Automatically detect IDE context (editor, chat, terminal)",
          "order": 13
        },
        "voiceScribe.maxRecordingDuration": {
          "type": "number",
          "default": 60,
          "minimum": 5,
          "maximum": 300,
          "description": "Maximum recording duration in seconds",
          "order": 14
        },
        "voiceScribe.prompt": {
          "type": "string",
          "default": "",
          "description": "Optional context prompt to improve transcription accuracy",
          "order": 15
        },
        "voiceScribe.responseFormat": {
          "type": "string",
          "enum": [
            "text",
            "json",
            "verbose_json"
          ],
          "default": "text",
          "description": "Response format from Whisper API",
          "enumDescriptions": [
            "Plain text response",
            "JSON with basic metadata",
            "Detailed JSON with timestamps and confidence"
          ],
          "order": 15.1
        },
        "voiceScribe.enableTimestamps": {
          "type": "boolean",
          "default": false,
          "description": "Include timestamps in transcription (requires JSON format)",
          "order": 15.2
        },
        "voiceScribe.silenceDetection": {
          "type": "boolean",
          "default": true,
          "description": "Automatically detect silence and stop recording",
          "order": 15.3
        },
        "voiceScribe.silenceThreshold": {
          "type": "number",
          "default": 2,
          "minimum": 0.5,
          "maximum": 10,
          "description": "Silence duration in seconds before auto-stop",
          "order": 15.4
        },
        "voiceScribe.temperature": {
          "type": "number",
          "default": 0.1,
          "minimum": 0,
          "maximum": 1,
          "description": "OpenAI temperature (0 = deterministic, 1 = creative)",
          "order": 16
        },
        "voiceScribe.timeout": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 120000,
          "description": "API request timeout in milliseconds",
          "order": 17
        },
        "voiceScribe.maxRetries": {
          "type": "number",
          "default": 3,
          "minimum": 0,
          "maximum": 10,
          "description": "Maximum number of retry attempts for failed API requests",
          "order": 18
        },
        "voiceScribe.retryDelay": {
          "type": "number",
          "default": 1000,
          "minimum": 100,
          "maximum": 10000,
          "description": "Delay between retry attempts in milliseconds",
          "order": 19
        },
        "voiceScribe.formatText": {
          "type": "boolean",
          "default": true,
          "description": "Format transcribed text (capitalize, trim whitespace)",
          "order": 20
        },
        "voiceScribe.addNewLine": {
          "type": "boolean",
          "default": true,
          "description": "Add new line after inserted text",
          "order": 21
        },
        "voiceScribe.indentToSelection": {
          "type": "boolean",
          "default": false,
          "description": "Indent inserted text to match selection",
          "order": 22
        },
        "voiceScribe.statusBarPosition": {
          "type": "string",
          "enum": [
            "left",
            "right"
          ],
          "default": "right",
          "description": "Position of status bar indicator",
          "order": 23
        },
        "voiceScribe.showTooltips": {
          "type": "boolean",
          "default": true,
          "description": "Show helpful tooltips in status bar",
          "order": 24
        },
        "voiceScribe.enableAnimations": {
          "type": "boolean",
          "default": true,
          "description": "Enable status bar animations",
          "order": 25
        },
        "voiceScribe.autoHideSuccess": {
          "type": "boolean",
          "default": true,
          "description": "Automatically hide success messages",
          "order": 26
        },
        "voiceScribe.successDuration": {
          "type": "number",
          "default": 2000,
          "minimum": 500,
          "maximum": 10000,
          "description": "Duration to show success messages (ms)",
          "order": 27
        },
        "voiceScribe.errorDuration": {
          "type": "number",
          "default": 3000,
          "minimum": 1000,
          "maximum": 10000,
          "description": "Duration to show error messages (ms)",
          "order": 28
        },
        "voiceScribe.baseURL": {
          "type": "string",
          "default": "",
          "description": "Custom OpenAI API base URL (leave empty for default)",
          "order": 29
        }
      }
    }
  },
  "scripts": {
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "compile-tests": "tsc -p . --outDir out",
    "compile": "npm run check-types && npm run lint && node esbuild.js",
    "test": "vscode-test",
    "test:unit": "npm run pretest && nyc mocha out/test/unit/**/*.test.js",
    "test:integration": "npm run pretest && nyc mocha out/test/integration/**/*.test.js",
    "test:coverage": "npm run pretest && nyc --reporter=html --reporter=text mocha out/test/**/*.test.js",
    "test:watch": "npm run compile-tests && mocha --watch out/test/**/*.test.js",
    "coverage:report": "nyc report --reporter=html --reporter=text",
    "coverage:check": "nyc check-coverage --lines 80 --functions 80 --branches 70 --statements 80",
    "check-types": "tsc --noEmit",
    "lint": "eslint src",
    "watch": "tsc -watch -p .",
    "package": "vsce package"
  },
  "devDependencies": {
    "@istanbuljs/nyc-config-typescript": "^1.0.2",
    "@types/mocha": "^10.0.10",
    "@types/nock": "^10.0.3",
    "@types/node": "20.x",
    "@types/sinon": "^17.0.4",
    "@types/vscode": "^1.74.0",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.5.2",
    "esbuild": "^0.25.3",
    "eslint": "^9.25.1",
    "mocha": "^11.5.0",
    "nock": "^14.0.4",
    "npm-run-all": "^4.1.5",
    "nyc": "^17.1.0",
    "sinon": "^20.0.0",
    "source-map-support": "^0.5.21",
    "typescript": "^5.8.3"
  },
  "nyc": {
    "extends": "@istanbuljs/nyc-config-typescript",
    "include": [
      "out/core/**/*.js",
      "out/ui/**/*.js",
      "out/utils/**/*.js",
      "out/integrations/**/*.js"
    ],
    "exclude": [
      "out/test/**/*.js",
      "out/**/*.test.js",
      "out/mocks/**/*.js"
    ],
    "reporter": [
      "text",
      "html",
      "lcov"
    ],
    "all": true,
    "check-coverage": true,
    "lines": 80,
    "statements": 80,
    "functions": 80,
    "branches": 70
  },
  "dependencies": {
    "task-master-ai": "^0.15.0"
  }
}
