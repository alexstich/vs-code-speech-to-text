{
  "name": "speech-to-text-whisper",
  "displayName": "Speech to Text with Whisper",
  "description": "Transform speech to text using OpenAI Whisper API with seamless VS Code and Cursor IDE integration",
  "version": "1.1.1",
  "publisher": "speak-y",
  "icon": "media/icon.png",
  "galleryBanner": {
    "color": "#1e1e1e",
    "theme": "dark"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/alexstich/vs-code-speech-to-text"
  },
  "bugs": {
    "url": "https://github.com/alexstich/vs-code-speech-to-text/issues"
  },
  "homepage": "https://github.com/alexstich/vs-code-speech-to-text#readme",
  "license": "MIT",
  "engines": {
    "vscode": "^1.74.0"
  },
  "categories": [
    "Other",
    "Chat",
    "AI"
  ],
  "keywords": [
    "speech",
    "voice",
    "transcription",
    "whisper",
    "openai",
    "audio",
    "ai",
    "cursor",
    "dictation",
    "accessibility",
    "ffmpeg",
    "cross-platform",
    "recording"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onCommand:speechToTextWhisper.recordAndInsertOrClipboard",
    "onCommand:speechToTextWhisper.recordAndOpenCurrentChat",
    "onCommand:speechToTextWhisper.runDiagnostics",
    "onCommand:speechToTextWhisper.openSettings",
    "onCommand:speechToTextWhisper.toggleMode"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "viewsContainers": {
      "activitybar": [
        {
          "id": "speechToTextWhisper",
          "title": "Speech to Text",
          "icon": "$(mic)"
        }
      ]
    },
    "views": {
      "speechToTextWhisper": [
        {
          "id": "speechToTextWhisper.deviceManager",
          "name": "Device Manager",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.modeSelector",
          "name": "Text insertion mode",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.settings",
          "name": "Settings",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.transcriptionHistory",
          "name": "Transcription History",
          "when": "true"
        },
        {
          "id": "speechToTextWhisper.diagnostics",
          "name": "Diagnostics",
          "when": "true"
        }
      ]
    },
    "commands": [
      {
        "command": "speechToTextWhisper.recordAndInsertOrClipboard",
        "title": "Record and Insert at Cursor or Clipboard",
        "category": "Speech to Text with Whisper",
        "icon": "$(edit)"
      },
      {
        "command": "speechToTextWhisper.recordAndOpenCurrentChat",
        "title": "Record and Open Current Chat",
        "category": "Speech to Text with Whisper",
        "icon": "$(comment-discussion)"
      },
      {
        "command": "speechToTextWhisper.runDiagnostics",
        "title": "Run Diagnostics",
        "category": "Speech to Text with Whisper",
        "icon": "$(debug-alt)"
      },
      {
        "command": "speechToTextWhisper.testFFmpeg",
        "title": "Test FFmpeg Availability",
        "category": "Speech to Text with Whisper",
        "icon": "$(tools)"
      },
      {
        "command": "speechToTextWhisper.testAudioRecorder",
        "title": "Test Audio Recorder Initialization",
        "category": "Speech to Text with Whisper",
        "icon": "$(debug-console)"
      },
      {
        "command": "speechToTextWhisper.openSettings",
        "title": "Open Settings",
        "category": "Speech to Text with Whisper",
        "icon": "$(settings-gear)"
      },
      {
        "command": "speechToTextWhisper.toggleMode",
        "title": "Toggle Recording Mode",
        "category": "Speech to Text with Whisper",
        "icon": "$(arrow-swap)"
      },
      {
        "command": "speechToTextWhisper.setMode",
        "title": "Set Recording Mode",
        "category": "Speech to Text with Whisper"
      },
      {
        "command": "speechToTextWhisper.audioSettings.selectDevice",
        "title": "Select Audio Device",
        "category": "Speech to Text with Whisper"
      },
      {
        "command": "speechToTextWhisper.transcriptionHistory.copyToClipboard",
        "title": "Copy to Clipboard",
        "category": "Speech to Text with Whisper",
        "icon": "$(copy)"
      },
      {
        "command": "speechToTextWhisper.transcriptionHistory.insertAtCursor",
        "title": "Insert at Cursor",
        "category": "Speech to Text with Whisper",
        "icon": "$(insert)"
      },
      {
        "command": "speechToTextWhisper.transcriptionHistory.deleteEntry",
        "title": "Delete Entry",
        "category": "Speech to Text with Whisper",
        "icon": "$(trash)"
      },
      {
        "command": "speechToTextWhisper.transcriptionHistory.clearHistory",
        "title": "Clear History",
        "category": "Speech to Text with Whisper",
        "icon": "$(clear-all)"
      },
              {
          "command": "speechToTextWhisper.transcriptionHistory.refresh",
          "title": "Refresh",
          "category": "Speech to Text with Whisper",
          "icon": "$(refresh)"
        }
      ],
    "keybindings": [
      {
        "command": "speechToTextWhisper.recordAndOpenCurrentChat",
        "key": "ctrl+shift+n",
        "mac": "cmd+shift+n"
      },
      {
        "command": "speechToTextWhisper.recordAndInsertOrClipboard",
        "key": "ctrl+shift+m",
        "mac": "cmd+shift+m"
      }
    ],
    "menus": {
      "view/title": [
        {
          "command": "speechToTextWhisper.recordAndInsertOrClipboard",
          "when": "view == speechToTextWhisper.diagnostics",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.recordAndOpenCurrentChat",
          "when": "view == speechToTextWhisper.diagnostics",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.runDiagnostics",
          "when": "view == speechToTextWhisper.diagnostics",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.openSettings",
          "when": "view == speechToTextWhisper.settings",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.transcriptionHistory.refresh",
          "when": "view == speechToTextWhisper.transcriptionHistory",
          "group": "navigation"
        },
        {
          "command": "speechToTextWhisper.transcriptionHistory.clearHistory",
          "when": "view == speechToTextWhisper.transcriptionHistory",
          "group": "navigation"
        }
      ],
      "view/item/context": [
        {
          "command": "speechToTextWhisper.transcriptionHistory.copyToClipboard",
          "when": "view == speechToTextWhisper.transcriptionHistory && viewItem == transcriptionText",
          "group": "inline@1"
        },
        {
          "command": "speechToTextWhisper.transcriptionHistory.insertAtCursor",
          "when": "view == speechToTextWhisper.transcriptionHistory && viewItem == transcriptionText",
          "group": "inline@2"
        },
        {
          "command": "speechToTextWhisper.transcriptionHistory.deleteEntry",
          "when": "view == speechToTextWhisper.transcriptionHistory && viewItem == transcriptionEntry",
          "group": "context@1"
        }
      ]
    },
    "configuration": {
      "title": "Speech to Text with Whisper",
      "properties": {
        "speechToTextWhisper.apiKey": {
          "type": "string",
          "description": "OpenAI API Key for Whisper transcription",
          "scope": "application",
          "order": 1
        },
        "speechToTextWhisper.language": {
          "type": "string",
          "default": "auto",
          "description": "Language for transcription (auto-detect if 'auto')",
          "enum": [
            "auto",
            "en",
            "ru",
            "es",
            "fr",
            "de",
            "it",
            "pt",
            "zh",
            "ja",
            "ko",
            "ar",
            "bg",
            "ca",
            "cs",
            "da",
            "el",
            "et",
            "fi",
            "he",
            "hi",
            "hr",
            "hu",
            "is",
            "id",
            "lv",
            "lt",
            "mk",
            "ms",
            "mt",
            "nl",
            "no",
            "pl",
            "ro",
            "sk",
            "sl",
            "sr",
            "sv",
            "th",
            "tr",
            "uk",
            "vi"
          ],
          "enumDescriptions": [
            "Auto-detect language",
            "English",
            "Russian",
            "Spanish",
            "French",
            "German",
            "Italian",
            "Portuguese",
            "Chinese",
            "Japanese",
            "Korean",
            "Arabic",
            "Bulgarian",
            "Catalan",
            "Czech",
            "Danish",
            "Greek",
            "Estonian",
            "Finnish",
            "Hebrew",
            "Hindi",
            "Croatian",
            "Hungarian",
            "Icelandic",
            "Indonesian",
            "Latvian",
            "Lithuanian",
            "Macedonian",
            "Malay",
            "Maltese",
            "Dutch",
            "Norwegian",
            "Polish",
            "Romanian",
            "Slovak",
            "Slovenian",
            "Serbian",
            "Swedish",
            "Thai",
            "Turkish",
            "Ukrainian",
            "Vietnamese"
          ],
          "order": 2
        },
        "speechToTextWhisper.whisperModel": {
          "type": "string",
          "enum": [
            "whisper-1"
          ],
          "default": "whisper-1",
          "description": "OpenAI Whisper model to use for transcription",
          "order": 3
        },
        "speechToTextWhisper.prompt": {
          "type": "string",
          "default": "This is a technical instruction about programming in Visual Studio Code IDE. The speaker provides step-by-step coding instructions related to features, extensions, debugging, and software development workflows.",
          "description": "Optional context prompt to improve transcription accuracy",
          "editPresentation": "multilineText",
          "order": 4
        },
        "speechToTextWhisper.temperature": {
          "type": "number",
          "default": 0.1,
          "minimum": 0,
          "maximum": 1,
          "description": "OpenAI temperature (0 = deterministic, 1 = creative)",
          "order": 5
        },
        "speechToTextWhisper.audioQuality": {
          "type": "string",
          "enum": [
            "standard",
            "high",
            "ultra"
          ],
          "default": "standard",
          "description": "Audio recording quality",
          "enumDescriptions": [
            "Standard quality (16kHz, adequate for most speech)",
            "High quality (44.1kHz, better accuracy)",
            "Ultra quality (48kHz, maximum accuracy)"
          ],
          "order": 6
        },
        "speechToTextWhisper.timeout": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 120000,
          "description": "API request timeout in milliseconds",
          "order": 7
        },
        "speechToTextWhisper.maxRetries": {
          "type": "number",
          "default": 3,
          "minimum": 0,
          "maximum": 10,
          "description": "Maximum number of retry attempts for failed API requests",
          "order": 8
        },
        "speechToTextWhisper.postProcessing.model": {
          "type": "string",
          "enum": [
            "Without post-processing",
            "gpt-4.1-2025-04-14",
            "gpt-4.1-mini-2025-04-14",
            "gpt-4.1-nano-2025-04-14",
            "gpt-4.5-preview-2025-02-27",
            "gpt-4o-2024-08-06",
            "gpt-4o-mini-2024-07-18",
            "gpt-4-turbo-2024-04-09",
            "gpt-3.5-turbo-0125",
            "o1-2024-12-17",
            "o1-mini-2024-09-12",
            "o3-2025-04-16",
            "o3-mini-2025-01-31",
            "o4-mini-2025-04-16",
            "chatgpt-4o-latest"
          ],
          "default": "gpt-4.1-mini-2025-04-14",
          "description": "Model for post-processing transcribed text to improve quality",
          "enumDescriptions": [
            "No post-processing - use original Whisper output",
            "GPT-4.1 (April 2025) - flagship model with specific date version",
            "GPT-4.1 Mini (April 2025) - compact flagship with date version (recommended)",
            "GPT-4.1 Nano (April 2025) - ultra-fast model with date version",
            "GPT-4.5 Preview (February 2025) - cutting-edge model with date",
            "GPT-4o (August 2024) - flagship model with specific date version",
            "GPT-4o mini (July 2024) - balanced model with specific date version",
            "GPT-4 Turbo (April 2024) - turbo model with specific date version",
            "GPT-3.5 Turbo (January 2025) - turbo model with date version",
            "o1 (December 2024) - reasoning model with specific date version",
            "o1-mini (September 2024) - compact reasoning with date version",
            "o3 (April 2025) - advanced reasoning model with date version",
            "o3-mini (January 2025) - compact reasoning model with date",
            "o4-mini (April 2025) - compact multimodal model with date",
            "ChatGPT-4o latest - continuously updated flagship model"
          ],
          "order": 9
        },
        "speechToTextWhisper.postProcessing.prompt": {
          "type": "string",
          "default": "Please improve this transcribed text by:\n1. Adding proper punctuation and capitalization\n2. Removing filler words (um, uh, like, you know)\n3. Always try to structure sentences for lists and paragraphs for better readability\n4. Maintaining the original meaning and technical terms\n5. Return improved text without any additional text or explanations\n\nOriginal text:",
          "description": "Custom prompt for post-processing to guide text improvement.\n\nHOW IT WORKS: The transcribed text from Whisper will be automatically appended to the end of your prompt with a space in between.\n\nExample:\nYour prompt: \"Please improve this text by fixing grammar:\"\nWhisper output: \"um so like the function uh returns a value\"\nFinal request to AI: \"Please improve this text by fixing grammar: um so like the function uh returns a value\"\n\nBest practices:\n- End your prompt with a colon (:) for clarity\n- Be specific about desired improvements\n- Keep it concise but descriptive\n- The AI will receive: [YOUR_PROMPT] + [SPACE] + [WHISPER_TEXT]",
          "editPresentation": "multilineText",
          "order": 10
        },
        "speechToTextWhisper.postProcessing.minTextLength": {
          "type": "number",
          "default": 50,
          "minimum": 0,
          "maximum": 1000,
          "description": "Minimum text length (characters) to trigger post-processing",
          "order": 11
        },
        "speechToTextWhisper.postProcessing.timeout": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 120000,
          "description": "Timeout for post-processing API requests in milliseconds",
          "order": 12
        },
        
        "speechToTextWhisper.silenceDetection": {
          "type": "boolean",
          "default": true,
          "description": "Automatically stop recording when silence is detected",
          "order": 13
        },
        "speechToTextWhisper.silenceDuration": {
          "type": "number",
          "default": 3,
          "minimum": 1,
          "maximum": 10,
          "description": "Duration of silence in seconds before automatically stopping recording",
          "order": 14
        },
        "speechToTextWhisper.silenceThreshold": {
          "type": "number",
          "default": 30,
          "minimum": 20,
          "maximum": 80,
          "description": "Silence threshold value (20-80). Higher values are more sensitive to silence.",
          "order": 15
        },
        "speechToTextWhisper.ffmpegPath": {
          "type": "string",
          "default": "",
          "description": "Path to FFmpeg executable (leave empty for auto-detection)",
          "scope": "application",
          "order": 16  
        },
        "speechToTextWhisper.showStatusBar": {
          "type": "boolean",
          "default": true,
          "description": "Show recording status in status bar",
          "order": 17
        },
        "speechToTextWhisper.maxRecordingDuration": {
          "type": "number",
          "default": 3600,
          "minimum": 5,
          "maximum": 7200,
          "description": "Maximum recording duration in seconds",
          "order": 18
        },
        "speechToTextWhisper.inputDevice": {
          "type": "string",
          "default": "auto",
          "description": "Audio input device for recording ('auto' for automatic detection)",
          "order": 19
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "node esbuild.js --production",
    "compile": "node esbuild.js",
    "compile:tsc": "tsc -p ./tsconfig.test.json",
    "watch": "node esbuild.js --watch",
    "pretest": "npm run compile:tsc && npm run lint",
    "lint": "eslint src",
    "test": "vscode-test",
    "test:unit": "mocha out/test/unit/**/*.test.js --timeout 5000",
    "test:integration": "vscode-test",
    "test:cursor": "npm run compile && vscode-test --grep \"Cursor Integration - Real IDE Tests\"",
    "package": "node esbuild.js && vsce package"
  },
  "devDependencies": {
    "@istanbuljs/nyc-config-typescript": "^1.0.2",
    "@types/mocha": "^10.0.10",
    "@types/nock": "^10.0.3",
    "@types/node": "20.x",
    "@types/sinon": "^17.0.4",
    "@types/tmp": "^0.2.6",
    "@types/vscode": "^1.74.0",
    "@types/which": "^3.0.4",
    "@typescript-eslint/eslint-plugin": "^8.31.1",
    "@typescript-eslint/parser": "^8.31.1",
    "@vscode/test-cli": "^0.0.10",
    "@vscode/test-electron": "^2.5.2",
    "esbuild": "^0.25.3",
    "eslint": "^9.25.1",
    "mocha": "^11.5.0",
    "nock": "^14.0.4",
    "npm-run-all": "^4.1.5",
    "nyc": "^17.1.0",
    "sinon": "^20.0.0",
    "source-map-support": "^0.5.21",
    "ts-node": "^10.9.2",
    "typescript": "^5.8.3"
  },
  "nyc": {
    "extends": "@istanbuljs/nyc-config-typescript",
    "include": [
      "out/core/**/*.js",
      "out/ui/**/*.js",
      "out/utils/**/*.js",
      "out/integrations/**/*.js"
    ],
    "exclude": [
      "out/test/**/*.js",
      "out/**/*.test.js",
      "out/mocks/**/*.js"
    ],
    "reporter": [
      "text",
      "html",
      "lcov"
    ],
    "all": true,
    "check-coverage": true,
    "lines": 80,
    "statements": 80,
    "functions": 80,
    "branches": 70
  },
  "dependencies": {
    "task-master-ai": "^0.15.0",
    "tmp": "^0.2.3",
    "which": "^5.0.0"
  }
}
